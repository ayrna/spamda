% !TeX spellcheck = en_GB
%  LaTeX support: latex@mdpi.com 
%  In case you need support, please attach all files that are necessary for compiling as well as the log file, and specify the details of your LaTeX setup (which operating system and LaTeX version / tools you are using).

%=================================================================
\documentclass[energies,article,accept,moreauthors,pdftex]{Definitions/mdpi} 

% If you would like to post an early version of this manuscript as a preprint, you may use preprint as the journal and change 'submit' to 'accept'. The document class line would be, e.g., \documentclass[preprints,article,accept,moreauthors,pdftex]{mdpi}. This is especially recommended for submission to arXiv, where line numbers should be removed before posting. For preprints.org, the editorial staff will make this change immediately prior to posting.

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% biologics, jmp, eng, jor, nursrep, biophysica, gastroent, jox, adolescents, hygiene, taxonomy, business, nanomanufacturing, geography, compoundsacoustics, actuators, addictions, admsci, aerospace, agriculture, agriengineering, agronomy, ai, algorithms, allergies, analytica, animals, antibiotics, antibodies, antioxidants, applmech, applnano, applsci, arts, asc, asi, atmosphere, atoms, automation, axioms, batteries, bdcc, behavsci , beverages, bioengineering, biology, biomedicines, biomedinformatics, biomimetics, biomolecules, biosensors, bloods, brainsci, breath, buildings, cancers, carbon , catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, chemproc, children, civileng, cleantechnol, climate, clockssleep, cmd, coatings, colloids, computation, computers, condensedmatter, cosmetics, cryptography, crystals, cyber, dairy, data, dentistry, dermatopathology, designs, diabetology, diagnostics, digital, diseases, diversity, drones, earth, econometrics, ecologies, economies, education, ejbc, ejihpe, electricity, electrochem, electronicmat, electronics, endocrines, energies, engproc, entropy, environments, environsciproc, epidemiologia, epigenomes, est, fermentation, fibers, fire, fishes, fluids, foods, forecasting, forests, fractalfract, fuels, futureinternet, futurephys, galaxies, games, gardens, gases, gastrointestdisord, gels, genealogy, genes, geohazards, geosciences, geriatrics, hazardousmatters, healthcare, hearts, heritage, highthroughput, horticulturae, humanities, hydrogen, hydrology, ijerph, ijfs, ijgi, ijms, ijtpp, immuno, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jcdd, jce, jcm, jcp, jcs, jdb, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmse, jne, jnt, jof, joitmc, journalmedia, jpm, jrfm, jsan, land, languages, laws, life, literature, livers, logistics, lubricants, machines, magnetochemistry, make, marinedrugs, materials, materproc, mathematics, mca, medicina, medicines, medsci, membranes, metabolites, metals, microarrays, micromachines, microorganisms, minerals, modelling, molbank, molecules, mps, mti, nanomaterials, ncrna, ijns, neurosci, neuroglia, nitrogen, notspecified, nutrients, obesities, oceans, ohbm, osteology, optics, organics, particles, pathogens, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photonics, physics, plants, plasma, pollutants, polymers, polysaccharides, preprints , proceedings, processes, prosthesis, proteomes, psych, psychiatryint, publications, quantumrep, quaternary, qubs, radiation, reactions, recycling, religions, remotesensing, reprodmed, reports, resources, risks, robotics, safety, sci, scipharm, sensors, separations, sexes, signals, sinusitis, skins, smartcities, sna, societies, socsci, soilsystems, solids, sports, standards, stats, surfaces, surgeries, suschem, sustainability, world, symmetry, systems, technologies, telecom, test, tourismhosp, toxics, toxins, transplantology, tropicalmed, universe, urbansci, uro, vaccines, vehicles, vetsci, vibration, viruses, vision, water, wem, wevj, women

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, benchmark, book, bookreview, briefreport, casereport, changes, comment, commentary, communication, conceptpaper, conferenceproceedings, correction, conferencereport, expressionofconcern, extendedabstract, meetingreport, creative, datadescriptor, discussion, editorial, essay, erratum, hypothesis, interestingimages, letter, meetingreport, newbookreceived, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, supfile, technicalnote, viewpoint
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. In addition,  line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figures are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================

%=================================================================
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{1}
\pubyear{2021}
\copyrightyear{2021}
%\externaleditor{Academic Editor: Firstname Lastname} % For journal Automation, please change Academic Editor to "Communicated by"
\datereceived{} 
\dateaccepted{} 
\datepublished{} 
\hreflink{https://doi.org/} % Please use \linebreak if need to do line break
%\updates{yes} % If there is an update available, un-comment this line

%% MDPI internal command: uncomment if new journal that already uses continuous page numbers 
%\continuouspages{yes}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx,epstopdf, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, soul, multirow, microtype, tikz, totcount, amsthm, hyphenat, natbib, hyperref, footmisc, url, geometry, newfloat, caption

\usepackage{textcomp, gensymb}
\usepackage{color}
%\usepackage[table]{xcolor}
\usepackage{epstopdf}
\usepackage[labelformat=simple]{subfig}
\renewcommand\thesubfigure{\normalfont(\textbf{\alph{subfigure}})}

\usepackage[T1]{fontenc}

\epstopdfsetup{outdir=./figures/}
\definecolor{gray090}{gray}{0.90}

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Building Suitable Datasets for Soft Computing and Machine Learning Techniques from Meteorological Data Integration: A~Case Study for Predicting Significant Wave Height and Energy~Flux}
%Attention AE/ME. The following layout issues have not been checked by the English Editing Department and must be carefully verified by the AE/Layout Department: All callout issues, bold usage of callouts, and references to callouts in the text. Correct callout usage in figures. Figure and Table layout issues. Footnote formatting and Glossaries have not been checked. En dash usage for negative values, en dash usage to indicate relationships, en dash usage to indicate bonds (especially in chemistry). The English Editing Department is not responsible for correct italic usage for genes, proteins and technical terminology. This responsibility belongs to the authors. The following are also not checked: spacing between numbers and units of measurement, ratios, en dashes for ranges, date and time formats, punctuation in equation lines, and less than/more than spacing (< >). Finally, capitalization and layout of titles/headings must be properly checked as well as ensuring 'Eq.' and 'Fig.' are properly spelled out, as these are layout issues.

% MDPI internal command: Title for citation in the left column
\TitleCitation{Building Suitable Datasets for Soft Computing and Machine Learning Techniques from Meteorological Data Integration: A Case Study for Predicting Significant Wave Height and Energy Flux}
% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0002-1929-2408} % Add \orcidA{} behind the author's name
\newcommand{\orcidauthorB}{0000-0001-8849-6036} % Add \orcidB{} behind the author's name
\newcommand{\orcidauthorC}{0000-0001-9773-6783} % Add \orcidC{} behind the author's name
\newcommand{\orcidauthorD}{0000-0002-2657-776X} % Add \orcidD{} behind the author's name
\newcommand{\orcidauthorE}{0000-0003-4564-1816}

% Authors, for the paper (add full first names)
%\Author{Firstname Lastname $^{1,\dagger,\ddagger}$\orcidA{}, Firstname Lastname $^{1,\ddagger}$ and Firstname Lastname $^{2,}$*}
\Author{Antonio Manuel G\'omez-Orellana\orcidA{}*, Juan Carlos Fern\'andez *\orcidB{}, Manuel Dorado-Moreno *\orcidC{}, Pedro~Antonio~Guti\'errez *\orcidD{} and C\'esar Herv\'as-Mart\'inez *\orcidE{}}


% Authors, for metadata in PDF
%\AuthorNames{Firstname Lastname, Firstname Lastname and Firstname Lastname}
\AuthorNames{Antonio Manuel G\'omez-Orellana, Juan Carlos Fern\'andez, Manuel Dorado-Moreno, Pedro Antonio Guti\'errez and C\'esar Herv\'as-Mart\'inez}

% MDPI internal command: Authors, for citation in the left column
\AuthorCitation{G\'omez-Orellana, A.M.; Fern\'andez, J.C.; Dorado-Moreno, M.; Guti\'errez, P.A.; Herv\'as-Mart\'inez, C.}
%If this is Chicago journal, please change author citation format as: Lastname, Firstname, Firstname Lastname, and First-name Last-name.
% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
%\address{%
%$^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
%$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}
\address{%
Department of Computer Science and Numerical Analysis, University of Cordoba, 14071 C\'ordoba, Spain}

% Contact information of the corresponding author
%\corres{Correspondence: e-mail@e-mail.com; Tel.: (optional; include country code; if there are multiple corresponding authors, add author initials) +xx-xxxx-xxx-xxxx (F.L.)}
\corres{\hangafter=1 \hangindent=1.05em \hspace{-0.82em} Correspondence: am.gomez@uco.es (A.M.G.-O.); jfcaballero@uco.es (J.C.F.); manuel.dorado@uco.es (M.D.-M.); pagutierrez@uco.es (P.A.G.); chervas@uco.es (C.H.-M.) }

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation 3} 
%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e., \\) 
\abstract{Meteorological data are extensively used to perform environmental learning. Soft Computing (SC) and Machine Learning (ML) techniques represent a valuable support in many research areas, but require datasets containing information related to the topic under study. Such datasets are not always available in an appropriate format and its preparation and pre-processing implies a lot of time and effort by researchers. This paper presents a novel software tool with a user-friendly GUI to create datasets by means of management and data integration of meteorological observations from two data sources: the National Data Buoy Center and the National Centers for Environmental Prediction and for Atmospheric Research Reanalysis Project. Such datasets can be created using buoys and reanalysis data through customisable procedures, in terms of temporal resolution, predictive and objective variables, and can be used by SC and ML methodologies for prediction tasks (classification or regression). The objective is providing the research community with an automated and versatile system for the casuistry that entails well-formed and quality data integration, potentially leading to better prediction models. The software tool can be used as a supporting tool for coastal and ocean engineering applications, sustainable energy production, or environmental modelling; as well as for decision-making in the design and building of coastal protection structures, marine transport, ocean energy converters, and well-planned running of offshore and coastal engineering activities. Finally, to illustrate the applicability of the proposed tool, a case study to classify waves depending on their significant height and to predict energy flux in the Gulf of Alaska is presented.}

% Keywords
\keyword{environmental prediction; renewable energy resource evaluation; meteorological data; reanalysis data; marine energy; soft computing}  % List three to ten pertinent keywords specific to the article, yet reasonably common within the subject discipline.

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences:
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:
%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%\setcounter{secnumdepth}{4}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{section}{-1} %% Remove this when starting to work on the template.

	\section{Introduction}
		
		A better understanding of the environment is of vital importance for science, contributing not only to more efficient exploitation of natural resources but also to the development of new strategies aimed at its protection. In that sense, meteorological observations provide an essential and valuable source of information which is widely used by researchers to address environmental learning, comprehension, prediction and conservation in numerous oceanic and atmospheric studies of a wide variety of areas (e.g., energy, climate change, agriculture, etc.). Some specific examples of the diversity of fields in which meteorological data can be used in are, among others: global solar radiation estimation \cite{SHAHRUKHANIS2019179}, directional analysis of sea storms \cite{LAFACE201545}, estimation of hybrid energy systems taking into account economic and environmental objectives\cite{Kumar2020}, wind power ramp events prediction \cite{DORADOMORENO2017428}, sea surface temperature prediction \cite{He2020}, study of the responses exhibited by plankton to fluid motions~\cite{FUCHS2016109}, trends in solar radiation \cite{SILVA20101852} or simulation of extreme near shore sea conditions \cite{GOULDBY201415}. All these studies require a prior data collection and its adaptation to a specific format that allows the interpretation of them.
		
		Once quality and well-formed data are obtained, these can be used to extract information and build prediction models that explain the behavior of a certain problem. The choice of the appropriate model, either in engineering problems or in any other problem, is also an important factor in addition to data \cite{Alizadeh2019, Alizadeh2020}. {In this sense, public and research organisms are increasingly promoting the use of open and robust datasets to boost policies coherent with the environmental exploitation, protection and conservation, as well as modelling tools available to the scientific community and decision-makers \cite{Manfren2020}}. Although Soft Computing (SC) and Machine Learning (ML) techniques have the ability to handle uncertainty in data and are extensively used for modelling purposes, the real challenge in modelling studies is due to the inadequacy of data, since the adequacy of the models depends mainly on the the quality of the information used, so that, if a researcher does not have quality data, there will be no quality models.
		
		Continuing with this line, special purpose software is usually developed to help researchers to advance in their studies related to energy and environmental modelling, becoming a great support for decision-making in the exploitation and protection of the environment. In \cite{Neeraj2020}, a software package in R called ``ForecastTB'' is developed for comparing the performance of distinct prediction methods, presenting the software as a stepping stone in ML automation modelling.
		In \cite{LO2015293}, an integrated simulation tool to optimise the design of bifacial solar panel with reflectors is presented. This tool can also be applied to study the efficiency of the solar cells. A framework for integrating information from offshore wind farms is implemented in \cite{NGUYEN2013150} in order to ease data interchange and enhance operation and maintenance practices. 
		In \cite{Roberta2020}, a new software tool named ``Storage LCA Tool'' is presented for comparing PCM---phase change materials- storage systems with conventional systems that do not involve energy storage, being beneficial for supporting decision-making on energy concepts for buildings.
		A risk assessment tool to improve safety standards and emergency management in onshore wind farms is presented in~\cite{ASTIASOGARCIA201648}. Raabe et al. \cite{RAABE2010213} developed two software tools, Model of Equilibrium of Bay Beaches (MEPBAY) and Coastal Modelling System (SMC), for supporting distinct operational levels of headland-bay beach in coastal engineering projects, and Motahhir et al. \cite{MOTAHHIR20199} developed an open hardware/software test bench for a solar tracker.
		
		Marine energy prediction is currently a hot topic where meteorological data are used. Marine Renewable Energy (MRE) is one of the most important renewable and sustainable energy sources available in our environment \cite{en12050787}, and it includes ocean thermal energy, marine tidal current energy and wave energy, among others. Its benefits and great \mbox{potential~\cite{ZEYRINGER20181281}} make it one of the most relevant natural resources, playing a crucial role not only in the reduction of the emission of greenhouse gases but also in all other aspects involved in the difficult challenge of the transition to a low carbon footprint \mbox{society \cite{en12091657, BREDE201344, Alizadeh2020a}}. Wave energy exhibits a more stable power supply than wind energy and even solar energy. In recent years, \textit{Wave Energy Converters} (WECs) \cite{FALCAO2010899} have been developed and widely installed, {even arranged in array form \cite{Amini2020}}, to transform this wave energy into electricity, which can be injected into the electric network or supplied to existing offshore oil and gas \mbox{platforms \cite{OLIVEIRAPINTO2019556}} or seawater desalination plants \cite{FERNANDEZPRIETO2019546}, among others. WECs are mechanical devices that convert kinetic energy into electrical energy through either the vertical oscillation or the linear motion of waves. Nevertheless, waves are difficult to be characterised due to their stochastic nature because of the influence of a large number of environmental factors that exert on them \cite{ochi1998}. As a consequence of this complexity, many aspects of WEC design, deployment and operation \cite{CROWLEY2018159, Abdelkhalik2016, 6898109} need a proper prediction of waves \cite{en11010011, Kaloop2020}, in order to maximise the wave energy extraction \cite{en80910370}. For this purpose, WECs use wave \textit{flux of energy} ($F_e$) which can be calculated from the two most relevant wave parameters related to this aspect: \textit{significant wave height} ($H_s$) and \textit{wave energy period} ($T_e$).
		
		\textls[-20]{Currently, and as a support to traditional study procedures, SC and ML \mbox{techniques \cite{Sang-Yong2014,Bishop:2006:PRM:1162264}}} are being widely used in numerous research fields related to classification, regression, and optimisation tasks, obtaining significant improvements in the performance of the results, either in engineering \cite{Alizadeh2020}, energy, or environmental problems \cite{Fi-John2019,Mosavi2019,GUO201816}. SC and ML methodologies can be used not only by experienced computer scientists but also by other researchers. For example, the well-known \textit{Waikato Environment for Knowledge Analysis} (WEKA) \cite{WEKA} software tool provides researchers with a wide collection of ML algorithms. ML techniques have been already applied to tackle wave characterisation, accurately estimating $H_{s}$ and $T_{e}$ parameters \cite{DURANROSAL2017268, KUMAR2017605}, given that robustness of ML methods can tackle the previously explained difficulties in wave energy prediction. In \cite{Ali2020}, a reliable ML model based on multiple linear regression and covariant-weighted least square estimation for $H_s$ modelling is presented in order to predict significant wave height 30 min in advance. In \cite{Cornejo-Bueno2016}, an approach for feature selection problems is developed and applied for $H_s$ and $F_e$ prediction in oceanic buoys, obtaining very good results. In \cite{Emmanouil2020}, a Bayesian Network system provides a helpful tool to support decision-making process of installation and maintenance operations in offshore wind farms using predictions of $H_s$, among others. In \cite{Shamshirband2020}, several ML methods are implemented and compared for the prediction of $H_s$ in the Persian Gulf, the extreme learning machine (ELM) providing the best results. The problem is that, in order to apply ML and SC techniques, it is essential to obtain datasets with relevant information about the issue under study, used to infer knowledge. Usually, these datasets are not publicly available in a friendly format, and their generation is the first step needed.
		
		The information to create these datasets related with MRE can be obtained from meteorological observations, but such information may be available in an inappropriate format and even contain missing values or measurements. Consequently, it is usually required to perform pre-processing tasks for improving the quality of the data, such as the replacement of missing values, outlier detection, or data normalisation, among others. Furthermore, if more than one source of information is used to achieve a better characterisation of the problem under study \cite{JOHANSSON2015143, FERNANDEZ201544, Adams2010}, then a data integration process, denominated as the matching process in this document, has to be carried out by researchers to manually create the datasets with the needed information. Given that such process is of great relevance and has an extensive casuistry, the present work has been specially focused on it. Moreover, depending on the subject and the SC and ML technique to be applied, or even if the researcher considers other factors in order to enhance the performance obtained or have more in-depth conclusions, the datasets would have to be updated afterwards. In summary, many important details and different intermediate steps have to be considered when creating suitable datasets, especially when data integration is required, resulting in an extremely tedious task.
		
		The main purpose of this paper is to present a new open source tool for the creation of datasets integrated by meteorological variables from two sources of information. Given that the tool provides a user-friendly graphical interface, no knowledge in programming languages is needed. It also prevents researchers from performing the mentioned tedious work and greatly simplifes all the steps involved in it, avoiding possible errors in the intermediate steps, at least as a preliminary study in certain areas where some kind of environmental prediction is needed. The meteorological data used by the tool come from two well-known sources of information: the \textit{National Oceanic and Atmospheric Administration} (NOAA) \textit{National Data Buoy Center} (NDBC) \cite{NOAA} and the \textit{National Centers for Environmental Prediction} (NCEP)/\textit{National Center for Atmospheric Research} (NCAR) \textit{Reanalysis Project} (NNRP or R1) \cite{Kalnay1996, Kistler2001}. The open source software tool presented in this work is named SPAMDA (Software for Pre-processing and Analysis of Meteorological DAta to build datasets), and it is available at \url{https://github.com/ayrna}. As SPAMDA performs all this data processing, it reduces the time involving these tasks and allows researchers to focus on the study of the meteorological aspects of the observations. The datasets obtained are ready to be used as input for SC and ML techniques in prediction tasks (classification or regression), although researchers can use them for other purposes. These datasets contain one or more meteorological variables as inputs and one variable as target (variable to be predicted). The format of the generated datasets will be \textit{Attribute-Relation File Format} (ARFF) \cite{WEKA_ARFF}, which is the one used by WEKA. In addition, the datasets can also be generated in \textit{Comma-Separated Values} (CSV) format, enabling researchers to use other tools.
		
		In order to address the problem previously discussed, meteorological data integration from NDBC and NNRP and the casuistry that it entails, SPAMDA offers to researchers novelties and functionalities that will be detailed in Section \ref{sec:SPAMDA}, although some of them are briefly summarised below:
		\begin{itemize}
			\item The generation of datasets becomes a very easy and customisable task by means of the selection of different input parameters, such as predictive and objective variables, classification and regression, output discretisation (useful for ordinal regression) or prediction horizon, among others.
			
			\item The created datasets can be easily used by SC and ML tools. 
			
			\item \textls[-10]{It makes the researcher focus on environmental modelling, without having to worry about the development of scripts or mechanical tasks, avoiding laborious pre-processing procedures that imply a great deal of time and endeavour in early stages of} \mbox{the~research.}
			
			\item It avoids possible researcher errors in the intermediate steps of the process, such as geographical coordinates conversion, missing values handling (dates or measurements not recorded) or different temporal resolution of the data collected, among others.
			
			\item It provides information about the quality and quantity of the data. SPAMDA allows preliminary studies of missing values (dates or measurements not recorded) in buoys managed by NDBC, so that the researcher can have an idea of the quality of the data recorded by the buoys and about their suitability for the intended purpose. In any case, SPAMDA allows data integration taking into account such missing values when needed by the user.
			
			\item Estimation of the amount of energy flux that can be produced at different prediction horizons: short-term, mid-term or long-term. Although this work does not focus on model performance, it should be taken into account that models tend to generalise worse with greater prediction horizons.
						
			\item It manages the extensive casuistry of data integration which can lead to incomplete datasets, described in Appendix \ref{app:AppendixA}.
			
			\item Possibility of selecting one or more reanalysis nodes near the localisation under study, which could provide a better description of the problem to achieve more \mbox{accurate models.}
			
			\item Although pre-processing is not the main objective of SPAMDA, the tool also provides some basic pre-processing filters on buoy measurements, such as normalisation and missing data recovery.
			
			\item It facilitates data management and well-organised storage of the datasets. Environmental studies in different geographical locations can be carried out by merely introducing and using other collected data.
			
			\item SPAMDA is distributed as an open source tool, its modular design allows the implementation of new modules for managing meteorological data from other sources, benefiting future renewable energy and environmental research.
			
			\item It includes a user-friendly GUI, facilitating and greatly simplifying data management, and it is integrated with the Explorer environment of WEKA.
			
			\item It is multi-platform, and it can be used on any computer with Java regardless of the operating system.
		\end{itemize}
		
		Therefore, the functionalities and characteristics that SPAMDA offers make it a supporting tool for researchers, which could be used in applications related to coastal and ocean engineering, and also in marine energy prediction. In \cite{Kumar2020}, the estimation of energy supply sources in hybrid energy systems is based on the amount of energy that can be obtained by a marine energy system within a prediction horizon. Regulation of WECs to avoid malfunction or breakage, depending on the significant wave height and/or energy flux expected, as well as the possibility of reconfiguring them in order to maximise the wave energy extraction, is studied in \cite{CROWLEY2018159, Abdelkhalik2016}. The prediction of the energy that could be obtained from a certain maritime location is considered in \cite{OLIVEIRAPINTO2019556, FERNANDEZPRIETO2019546} in order to know whether it is convenient to install WECs as power supply in marine structures, such as offshore oil and gas platforms or seawater desalination plants. In \cite{Ali2019}, significant wave height forecasting is applied for decision-making in exploitation and environmental protection for the construction of marine energy storage plants, future strategies on renewable energy and coastal planning. Other examples of application are: design of offshore structures and ports \cite{CHATZIIOANNOU2017126}, decision-making and risk assessment about operational works in the sea \cite{DALGIC2015211}, security systems for structures or naval security \cite{Spaulding2020}.
					
		This paper is organised as follows: Section \ref{sec:DataSources} describes the sources of information used by SPAMDA for creating datasets. Section \ref{sec:SPAMDA} describes in detail the features of the software tool. Section \ref{sec:CaseStudy} shows a case study describing the use of SPAMDA in a practical approach. Section \ref{sec:Conclusions} provides the final conclusions and future work.
		
	\section{Meteorological Data Sources}\label{sec:DataSources}
		
		The data provided by the above-mentioned sources of information of SPAMDA is described below:
		\begin{itemize}
						
			\item NDBC belongs to the \textit{National Weather Service} (NWS) and operates and supports a network of marine and ocean buoys that record data. The mission of the network is to record marine and ocean meteorological data, such as $H_s$, dominant wave period, or wind speed and direction, among others.

			The buoys maintained by NDBC are located in coastal and offshore waters, and they are provided with specific sensors and devices which allow them to perform measurements. The information collected by the buoys is available on the NDBC website \cite{NOAA_1}, and it is divided into different groups. One of them corresponds to standard meteorological information of the historical data collected by each buoy, which can be downloaded as annual text files and whose format was adopted by NDBC since January 2007 \cite {NOAA_2}. These files contain hourly measurements per day from $00$:$50$ to $23$:$50$ UTC (Universal Time Coordinated) and from $23$:$50$ 31 December of the previous desired year to $22$:$50$ 31 December of the desired year. In Table \ref{tab:measurementsDescription}, a comprehensive measurement description and the corresponding units are provided as a summary for the reader. A fragment of one of these files, which contains the measurements collected during year $2017$ by the buoy identified as \textit{Station 46001} in NDBC, is shown in Figure \ref{fig:fragmentAnnualTexFile}. Each column corresponds to a meteorological variable or attribute, and each row or instance corresponds to the values of the measurements collected by the buoy for each attribute at a specific date and time.

			\begin{figure}[H]
%				\centering
				\includegraphics[scale=0.5]{figures/FigureFragmentAnnualTextFile.png}
				\caption{A fragment of an annual text file of the \textit{Station 46001}.}
				\label{fig:fragmentAnnualTexFile}
			\end{figure}
			Note that the data collected by the network of buoys may be incomplete due to diverse circumstances such as the weather conditions in which the buoys have to operate, failures or malfunctioning elements of the buoys, among others. Accordingly, it may be the situation that some of the measurements are completely missing (missing date or instance) or partially missing (some measurements not recorded), by a buoy or by a set of buoys, once in a while or over a period of time. It may be also possible that the measurements have been recorded at a time different from the expected one. These aspects have to be taken into account when creating the datasets. This casuistry is explained in detail in Appendix \ref{app:AppendixA}.
	
			
			
			
			\item NNRP provides three-dimensional global reanalysis of numerous meteorological observations (e.g., components  \textit{Zonal} and \textit{Meridional} of the velocity of the wind, relative humidity, pressure, etc.), which is available monthly, daily, and every six hours at $00$ Z (Zulu time), $06$ Z, $12$ Z, and $18$ Z from $1948$ on a global $2.5\degree$ $\times$ $2.5\degree$ grid. Weather observations are from different sources, such as ships, satellites, and radar, among others. Reanalysis data are created assimilating such observations employing the same climate model along the whole period of reanalysis in order to decrease the impact of modelling changes on climate statistics. Such information has become a substantial support of the needs of the research community, even more in locations where instrumental (real time) data are not available.
 
 \begin{specialtable}[H] 
			
				\caption{Measurements descriptions and units of each meteorological variable or attribute collected by the buoys (a detailed description can be found in NDBC website \cite{NOAA_4}).}
				\label{tab:measurementsDescription}
%				\footnotesize
%				\centering
				
				\setlength{\cellWidtha}{\columnwidth/3-2\tabcolsep-1.2in}
\setlength{\cellWidthb}{\columnwidth/3-2\tabcolsep-1.2in}
\setlength{\cellWidthc}{\columnwidth/3-2\tabcolsep+2.4in}
\scalebox{1}[1]{\begin{tabularx}{\columnwidth}{>{\PreserveBackslash\centering}m{\cellWidtha}>{\PreserveBackslash\centering}m{\cellWidthb}>{\PreserveBackslash\raggedright}m{\cellWidthc}}
\toprule
					
					\textbf{Attribute}&\textbf{Units}&\textbf{Description}\\
 
					\midrule
					
					WDIR & degT & The direction the wind is coming from true North. \\ \midrule
					
					WSPD &  m/s & The speed of the wind. \\ \midrule
					
					GST &  m/s & Peak of gust speed. \\ \midrule
					
					WVHT &  m &  Significant wave height. \\ \midrule
					
					DPD & sec & Dominant wave period (maximum wave energy). \\ \midrule
					
					APD &  sec & Average wave period of all waves. \\ \midrule
					
					MWD & degT & The direction from which the waves at the dominant period are coming. \\ \midrule
					
					PRES &  hPa &  Sea level pressure. \\ \midrule
					
					ATMP & degC & Air temperature. \\ \midrule
					
					WTMP &  degC & Sea surface temperature.\\ \midrule
					
					DEWP & degC & Dewpoint temperature. \\ \midrule
					
					VIS &  nmi &  Visibility of the station. \\ \midrule
					
					TIDE & ft & The water level. \\
					
					\bottomrule
						
				\end{tabularx}}
			 
			    \end{specialtable}
			
			\textls[-20]{The reanalysis data are available in the NNRP website \cite{NNRP}, which is accessible through different sections. Such data can be fully (a global $2.5\degree$ $\times$ $2.5\degree$ grid) or partially (only the desired reanalysis nodes or sub-grid) downloaded as \textit{Network Common Data Form} (NetCDF) files \cite{NetCDF}, a special binary format for representing scientific data, which provides a description of the file contents and also includes the spatial and temporal properties of the data. Each reanalysis file contains the values of a meteorological variable estimated by a mathematical model for each reanalysis node. For the sake of clarity, in \mbox{Figure \ref{fig:subGrid}}, an example to approximately illustrate a sub-grid containing six~nodes of reanalysis surrounding the geographic localisation of a buoy (obtained from NDBC) is shown.}
			
			\begin{figure}[H]
%				\centering
				\includegraphics[scale=0.56]{figures/FigureSubGrid.jpg}
				\caption{Sub-grid representation of six nodes of reanalysis surrounding the \textit{Station 46001}.}
				\label{fig:subGrid}
			\end{figure}
			
		\end{itemize}
		
		Therefore, with both sources of information, which complement each other, and carrying out a matching process, SPAMDA will create datasets for prediction tasks. In this way, the dataset input variables will be one or more reanalysis variables from NNRP and one or more measurements from NDBC. The dataset output variable will always be one measurement from NDBC.
		
		
		
	\section{SPAMDA}\label{sec:SPAMDA}
		
		SPAMDA combines meteorological information from NDBC and NNRP to obtain new datasets for oceanic and atmospheric studies. In order to do so, SPAMDA manages three different types of datasets which are described in the following sections, but are briefly introduced bellow for giving the reader a better general understanding:
			\begin{itemize}
				\item \textit{Intermediate datasets}: They contain the meteorological observations from NDBC.
				\item \textit{Pre-processed datasets}: They are obtained as a result of pre-processing tasks performed on the intermediate datasets.
				\item \textit{Final datasets}: Created by merging an intermediate or pre-processed dataset (which contain the information from NDBC) with the reanalysis data from NNRP. This procedure is referenced in SPAMDA as a matching process and will be carried out according to the study to be performed (classification or regression).
			\end{itemize}
		
		
		SPAMDA consists of three main functional modules, whose main features, represented in Figure \ref{fig:SPAMDA}, are the following:
		\begin{itemize}
			
			
			\item \textit{Manage buoys data}: The aim of this module is to provide features for the management and analysis of the information related to the buoys from NDBC. This includes:
			\begin{enumerate}
				\item Entering and updating the information of each buoy.
				\item Creation of intermediate datasets with the collected measurements.
				\item Pre-processing tasks for obtaining the pre-processed datasets.
				\item Matching process to merge the information from NDBC and NNRP.
				\item Creation of the final datasets according to the ML technique to use (classification or regression).
			\end{enumerate}
			
			\item \textit{Manage reanalysis data}: This module is used for the management of the reanalysis data provided by the NNRP. In this way, researchers can keep the reanalysis data files updated for their studies. Such files will be used, depending on researchers' needs, in the matching process when obtaining the final datasets.
			
			\item \textit{Tools}: This module includes features for converting intermediate or pre-processed datasets to ARFF or CSV format and for opening ARFF files with WEKA software.
			
		\end{itemize}

		In the following subsections, each integrated functional module is described in detail.

% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
\widefigure
			\includegraphics[scale=0.38]{figures/FigureSPAMDA.eps}
			\caption{Brief outline of the functionality provided by SPAMDA.}
			\label{fig:SPAMDA}
		\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn
\vspace{-12pt}

		
			\subsection{Buoys}\label{sec:Buoys}
			
				When a new buoy is included in SPAMDA, the following information, which can be obtained from NDBC, is requested:
				\begin{itemize}
					\item \textit{Station ID}: An alphanumeric identifier that allows easy identification of the buoy.
					\item \textit{Description}: A short description of the buoy.
					\item \textit{Latitude}: North or South geographical localisation (degrees) of the buoy.
					\item \textit{Longitude}: West or East geographical localisation (degrees) of the buoy.
					\item \textit{Measurements files}: The above-mentioned annual text files of the standard meteorological information recorded by the buoy and downloaded from the NDBC website. This will be used for the creation of the intermediate datasets. One file per year is expected.
				\end{itemize}
				
				For clarification, an example is presented in Figure \ref{fig:buoys}, where the buoy ID1 has three annual text files and the buoy ID2 has two annual text files.
				
				\begin{figure}[H]
%					\centering
					\includegraphics[scale=0.4]{figures/FigureBuoys.eps}
					\caption{Example of entering two buoys with its annual text files.}
					\label{fig:buoys}
				\end{figure}


			\subsection{Datasets}\label{sec:Datasets}
			
				Once a buoy has been included as described in Section \ref{sec:Buoys}, it is possible to create datasets with one or more annual text files, which are referenced in SPAMDA as intermediate datasets. In this module, researchers can manage intermediate datasets of each buoy, which are the baseline for their studies, by creating new ones or deleting the unnecessary~ones.
				
				When an intermediate dataset is created, it is associated with its corresponding buoy. In addition, a summary of its content is also created, providing relevant information such as the number of instances, the dates of the first and last measurements, the annual text files included and the missing and duplicated dates.
				
				An example where three intermediate datasets have been created is presented in \mbox{Figure \ref{fig:datasets}}. The two intermediate datasets of the buoy ID1 contain meteorological data of different years, and the intermediate dataset of the buoy ID2 contains meteorological data of two years. For each buoy, as many intermediate datasets as needed can be created.
				
				\begin{figure}[H]
%					\centering
					\includegraphics[scale=0.4]{figures/FigureDatasets.eps}
					\caption{Example of the creation of the intermediate datasets.}
					\label{fig:datasets}
				\end{figure}
				
				
			\subsection{Pre-Process} \label{sec:Preprocess}
				
				Data pre-processing prepares the raw data (intermediate datasets) to be able to be treated correctly by ML algorithms. This action can enhance the quality of data before the learning phase, by applying pre-processing tasks (filters). The result will be referenced as pre-processed datasets.
				
				SPAMDA provides several filters grouped in three categories, \textit{Attribute}, \textit{Instance}, and \textit{Recover missing data}, including the configuration of their parameters and a short description of them:
				\begin{itemize}

				 \item \textit{Attribute}: All of these filters can be applied to the attributes (variables of the buoy from NDBC) of the intermediate dataset.
				 
					\begin{itemize}
						\item \textit{Normalize}: This filter normalises all numeric values of each attribute. The resulting values are by default in the interval [0,1].
						\item \textit{Remove}: It removes an attribute or a range of them.
						\item \textit{RemoveByName}: It removes attributes based on a regular expression matched against their names.
						\item \textit{ReplaceMissingValues}: For each attribute, all the missing values will be replaced by the average value of the attribute.
						\item \textit{ReplaceMissingWithUserConstant}: This filter replaces all the missing values of the attributes with a user-supplied constant value.
					\end{itemize}
				 
				 \item \textit{Instance}: All these filters can be applied to the instances (hourly measurements of the buoy from NDBC) of the intermediate dataset.
					\begin{itemize}
						\item \textit{RemoveDuplicates}: With this filter, all duplicated instances are removed.
						\item \textit{RemoveWithValues}: This filter removes all the instances that match the attribute and the value supplied by the user.
						\item \textit{SubsetByExpression}: It removes all the instances that do not match a user-specified expression.
					\end{itemize}
				 
				 \item \textit{Recover missing data}: All these filters can be applied to the instances of the intermediate~dataset.
					\begin{itemize}
						\item \textit{Replace missing values with next nearest hour}: The missing values of each attribute are replaced with the next nearest non missing value.
						\item \textit{Replace missing values with previous nearest hour}: This filter replaces the missing values of each attribute with the previous nearest non missing value.
						\item \textit{Replace missing values with next $n$ hours mean}: The missing values of each attribute are replaced with the next $n$ nearest non missing values mean, where $n$ can be configured by the user.
						\item \textit{Replace missing values with previous $n$ hours mean}: This filter replaces the missing values of each attribute in the intermediate dataset with the previous $n$ nearest non missing values mean.
						\item \textit{Replace missing values with symmetric $n$ hours mean}: The missing values of each attribute in the intermediate dataset are replaced with the $n$ previous and $n$ next non missing values mean.
					\end{itemize}
				 
				\end{itemize}
				
				SPAMDA allows researchers to undo the last filter applied or to restore the initial content of the intermediate dataset. In addition, the content and relevant statistical information of the intermediate and the pre-processed datasets can be visualised in this module, for example: minimum and maximum values, mean, standard deviation, or even the number of instances with missing values.
				
				Figure \ref{fig:preprocess} shows an example where the intermediate datasets 1 and 2 of the buoy ID1 have been pre-processed, obtaining as a result the pre-processed dataset 1 of each one. The intermediate dataset 1 of the buoy ID2 has been also pre-processed. \textit{Pre-processed dataset n} represents that researchers can create as many pre-processed datasets as they consider~opportune.
				
				\begin{figure}[H]
%					\centering
					\includegraphics[scale=0.45]{figures/FigurePreprocess.eps}
					\caption{Example of the creation of pre-processed datasets.}
					\label{fig:preprocess}
				\end{figure}
				
				Nevertheless, further pre-processing tasks can be performed after obtaining the final datasets by means of the Explorer environment of WEKA or other tools.
				
				
			\subsection{Matching Configuration}
			\label{sec:matching_conf}
			
				The automatic integration of the data provided by the two sources of information described in Section \ref{sec:DataSources}, to merge and format such data, is denominated as the matching process in this document. Such process is one of the most powerful and remarkable features of this software tool due to its great relevance and extensive casuistry. In this sense, SPAMDA has been developed to provide great flexibility to researchers.
				
				The matching procedure is performed using an intermediate or pre-processed dataset, which includes the measurements collected by a buoy from NDBC, and the needed reanalysis data files from NNRP. Note that SPAMDA is able to manage the NetCDF binary format for handling the information stored in the reanalysis files.
				
				Such process merges the information of both sources that match on time, but, given that the reanalysis data are available with a minimum time horizon of $6$ h at $00$ Z, \mbox{$06$ Z}, \mbox{$12$ Z} and $18$ Z, and the measurements of the buoys are recorded at hourly intervals, from $00$:$50$ to $23$:$50$ UTC, the
%Please confirm if the time format is correct 				
matching can only be carried every six hours (discarding the rest of measurements from the buoy data). In addition, and since there is still a difference of 10 min, the matching with the reanalysis data will be performed with the nearest buoy measurement (before or after) within a maximum of 60 min of difference. Finally, the matched instances of both sources will form the final datasets.
				
				Figure \ref{fig:matchingProcess} presents an example of matching with the measurements collected during $2017$ by \textit{Station 46001} (NDBC) and the reanalysis data (NNRP) of the variable \textit{pressure} for reanalysis nodes $57.5$ N $\times$ $147.5$ W and $55.0$ N $\times$ $147.5$ W in the same year. In this way, only the instances from both sources that are linked with arrows (highlighted in green) will be used in the creation of the final datasets. Although the reanalysis dates have been presented in a human readable format, note that reanalysis dates are stored in hours from $01$-$01$-$1800$, and they have to be transformed for comparison taking into account the time zone. Such transformation is automatically done by SPAMDA when matching the~instances.
				
				The reader can check in Appendix \ref{app:AppendixA} for an example with a more complex case of the procedure.
				
				
				SPAMDA allows researchers to perform a customisable matching process, for obtaining as many different versions of the same meteorological data as needed.
				Prediction tasks are based on the estimation of the output attribute using the information provided by the input attributes. Depending on the task, the datasets must be prepared and \mbox{configured~differently}:
				\begin{itemize}
					\item \textit{Classification}: The final datasets will be ready to use as an input for ML classifiers, requiring a nominal output attribute, whose specific preparation is detailed in \mbox{Section \ref{sec:FinalDatasets}}.
					\item \textit{Regression}: The final datasets will be ready to use as input for regression methods, requiring a real output attribute, whose preparation is also explained in Section \ref{sec:FinalDatasets}.
					\item \textit{Direct matching}: In this case, the inputs' attributes have a direct correspondence with the output attribute, and it is not necessary to perform any additional preparation. Both input and target attributes are synchronised in time, in such a way that the final dataset is not intended for prediction purposes. For example, the final datasets may be used in lost data recovering tasks, in correlation studies, in descriptive \mbox{analyses, etc}.
				\end{itemize}
				
				The following parameters can be specified for the matching process:
				\begin{itemize}
				
					\item \textit{Flux of energy} \cite{FERNANDEZ201544}: When the $F_e$ is selected, it will be used as output. This attribute is not collected by the buoys, but there are two parameters from which it can be computed: $H_s$ and $T_e$, which are collected as WVHT and APD attributes, respectively, and were described in Table \ref{tab:measurementsDescription}. In this way, SPAMDA obtains the $F_e$ (measured in kilowatts per meter) of each instance using the following equation:
					\begin{equation}
							F_e = 0.49 \cdot H^2_s \cdot T_e,
							\label{eq:fluxOfEnergy}
					\end{equation}
where $H_s$ is measured in meters and $T_e$ in seconds. $F_e$ is referred to as flux of energy, but it is defined as an average energy flux because $H_s$ is an average wave height (see descriptions of the measurements on the NDBC website).
					
					\item \textit{Attribute to predict}: Instead of using $F_e$, researchers can select any of the attributes collected by the buoys as output (e.g., significant wave height, WVHT, wind direction, WDIR, sea level pressure, PRES, etc.). Therefore, they can conduct different studies by selecting one attribute or other.

					\item \textit{Reanalysis data files}: In order to have a possible better description of the problem under study, more than one reanalysis variable can be considered as input. Remember that these files have to be previously downloaded from the NNRP website \cite{NNRP}, which should set the range of dates (temporal properties) and the desired sub-grid (spatial properties, see Figure \ref{fig:subGrid}) for each variable of reanalysis.
					
					In that sense, the reanalysis data files must have the same spatial and temporal properties but related to different variables. SPAMDA simplifies this task by showing the reanalysis data files that are compatible with each other, and checking that the selection made by the research meets that condition.
					
					\item \textit{Buoy attributes}: In addition to the reanalysis variables, the final datasets will also include the selected attributes as inputs (of the intermediate or pre-processed dataset used), providing a possible better characterisation of the problem under study, although it will depend on how correlated the attributes are.

					\item \textit{Include missing dates}: As above-mentioned, the information collected by a buoy may be incomplete due to measurements not recorded by it. As a consequence, the matching of instances between both sources of information may not be possible (missing dates). In that situation, researchers can consider two options: (1) discard the instances affected or (2) include them. In the latter case, the final datasets will contain the affected instances, but the measurements of the buoy will be stored as missing values in WEKA format, denoted as \guillemotleft?\guillemotright.
					
					\item \textit{Nearest reanalysis nodes to consider}: As already shown in Figure \ref{fig:subGrid} (which represents six reanalysis nodes), the reanalysis data files may contain information of several reanalysis nodes. In this way, researchers can:
					
						\begin{itemize}
							
							\item Consider all the reanalysis nodes contained in each file: in this case, the information provided by each reanalysis node contained in each selected reanalysis data file will be used.
							
							\item Consider only some of the reanalysis nodes contained in each file: in this case, the information used is only that corresponding to the closest nodes to the buoy (the number of nodes, $N$, is indicated by the user). To do that, SPAMDA uses the \textit{Haversine} equation \cite{Haversine_2009} (or the great-circle distance) to calculate the distance from the location of the buoy to each node of reanalysis and obtain the closest ones. The Haversine equation performs calculation from main point to destination point with a trigonometric function:
								\begin{eqnarray}
									\label{eq:Haversine}
									d(p_0,p_j) & = & \arccos(\sin(lat_0)\cdot \sin(lat_j) \nonumber \\
									& & \cdot \cos(lon_0-lon_j) + \cos(lat_0) \\
									& & \cdot \cos(lat_j)), \nonumber 
								\end{eqnarray}
where $p_0$ is the geographical location of the buoy and $p_j$ is the position of each node. Finally, $lat$ and $lon$ represent the latitude and longitude of the positions of the points.
						\end{itemize}
					
					\item \textit{Number of final datasets}: Depending on the number of nearest reanalysis nodes to consider, the number of final datasets to create and the content of them can be configured according to the following options:
						\begin{itemize}
						
							\item \textit{One (using weighted mean of the $N$ nearest reanalysis nodes)}: Only one final dataset will be created, which will contain the attributes (the selected one as output and the selected ones as inputs) of the intermediate or pre-processed dataset used, along with a weighted mean of each variable of the reanalysis data used (one~per selected reanalysis data file). This weighted mean is obtained by SPAMDA and uses Equation (\ref{eq:Haversine}) to calculate the distance from the geographical position of the buoy to each node of reanalysis. Once the distances have been computed, they are normalised and inverted as shown in the following equation:
								\begin{linenomath*}
									\begin{equation}
										w_i=\frac{d(p_0,p_i)}{\sum_{j=1}^{N} d(p_0,p_j)}, ~~i=1, \ldots, N.
										\label{eq:weightedMean}
									\end{equation}
								\end{linenomath*}

							Then, with these calculated weights, a weighted mean of each variable of reanalysis is obtained for each of the $N$ nodes. In this way, the closest reanalysis nodes to the geographical position of the buoy will provide more information.
							
							\textls[-20]{Considering as an example the two nearest reanalysis nodes represented in \mbox{Figure \ref{fig:subGrid}} and the reanalysis variables air temperature and pressure, the weighted mean of each reanalysis variable will be calculated using the reanalysis nodes \mbox{$57.5$ N $\times$ $147.5$ W} and $55.0$ N $\times$ $147.5$ W.}
							
							\item \textit{`N' (one per each reanalysis node)}: As many final datasets as the number of nearest $N$ reanalysis nodes configured by researcher will be created. Therefore, each final dataset will contain the value of each reanalysis variable used of the nearest corresponding reanalysis node, along with the selected attributes of the intermediate or pre-processed dataset used. In this way, researchers can perform comparison studies depending on the reanalysis node considered, to achieve better performance for the problem under study.
							
							In this case, and considering as example the four closest reanalysis nodes (see \mbox{Figure  \ref{fig:subGrid}}) and the reanalysis variables air temperature and pressure, four final datasets will be created, each one containing the information of both reanalysis variables of the corresponding reanalysis node: $57.5$ N $\times$ $147.5$ W, \mbox{$55.0$ N $\times$ $147.5$ W}, $57.5$ N $\times$ $150.0$ W and $55.0$ N $\times$ $150.0$ W, along with the selected attributes of the intermediate or pre-processed dataset used.
							
						\end{itemize}
					
				\end{itemize}
						
				Once the matching parameters have been described, for a better understanding of them, Figure \ref{fig:directMatching} presents an example of the data integration considering the data shown in Figure \ref{fig:matchingProcess} and using the following configuration (Note that the date is shown just for a better understanding, but it will not be included in the final dataset):
					\begin{itemize}
						\item Attribute to predict: variable WVHT (Figure  \ref{fig:directMatching}a/flux of energy (Figure  \ref{fig:directMatching}b).
						\item Variable Pres as reanalysis input attribute.
						\item Variable WSDP as buoy input attribute.
						\item Not including missing dates.
						\item Considering the closest reanalysis node.
						\item Task to be used: \textit{Direct matching}.
					\end{itemize}
					
				% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
	\begin{figure}[H]
\widefigure
					\includegraphics[scale=0.42]{figures/FigureMatchingProcess.png}
					\caption{An example of matching the data from NDBC (\textbf{left}) and NNRP (\textbf{right}).}
					\label{fig:matchingProcess}
				\end{figure}
\vspace{-6pt}

				\begin{figure}[H]
\widefigure
					\subfloat[attribute to predict: WVHT\label{fig:directMatchingWave}]{\includegraphics[width=0.35\textwidth]{figures/FigureDirectMatching.png}}\hspace{24pt}
					\subfloat[attribute to predict: flux of energy\label{fig:directMatchingFlux}]{\includegraphics[width=0.42\textwidth]{figures/FigureDirectMatching_EF.png}}
					\caption{Example of data integration for \textit{Direct matching}.} \label{fig:directMatching}
				\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn

			\vspace{-12pt}	
			\subsection{Final Datasets} \label{sec:FinalDatasets}

				Once the matching process has been performed with the desired configuration, it is necessary to prepare the matched information for the desired prediction task (\textit{Regression} or \textit{Classification}), obtaining as a result the final datasets. Remember that \textit{Direct matching}, as it was described in Section \ref{sec:matching_conf}, performs a direct correspondence between the attributes used as inputs and the output one, and it is not necessary to carry out any preparation.
				
				SPAMDA allows researchers to make such preparation by means of the\linebreak following~options:
				
					\begin{itemize}

						\item \textit{Prediction horizon} (Classification and Regression): This option indicates the time gap for moving backward the attribute to predict (output attribute). In this way, the input attributes (variables of the buoy and reanalysis data) will be used to predict the output attribute in a specific future time (e.g., +6 h, +12 h, +18 h, +1 day, etc.).
						
						The minimum interval for increasing and decreasing the prediction horizon is $6$ h (due to reanalysis data temporal resolution) \cite{DORADOMORENO2017428}, the same interval used when the matching process is carried out. Therefore, for each increment of the prediction horizon, an instance of the dataset is lost (as this future information is not available). As the minimum prediction horizon is $6$ h, at least one instance will be lost. The relation between the inputs and the output (attribute to predict) is defined as follows:
						\begin{linenomath*}
							\begin{equation}
								o_{t+\Delta t}=\phi(\mathbf{b}_t,\mathbf{r}_{t}),
								\label{eq:noSynchronisingRD}
							\end{equation}
						\end{linenomath*}
						where $t$ is the time instant to study, $\Delta t$ is the prediction horizon, $o$ is the attribute to be predicted, $\mathbf{b}_t$ represents the vector that contains the selected NDBC variables, and, finally, $\mathbf{r}_t$ represents the vector that contains the selected reanalysis variables. In this way and considering the matched information shown in Figure \ref{fig:directMatching}a, WVHT is $o$, the vector $\mathbf{b}$ contains the variable WSPD, and the vector $\mathbf{r}$ contains Pres.
						
						Optionally, the reanalysis variables can be synchronised with the attribute to predict. Given that these variables are estimated by a mathematical model, we can obtain very good future estimations, which can improve the performance of the results. In this case, the relation between the inputs and the attribute to predict would be:
						\begin{linenomath*}
							\begin{equation}
								o_{t+\Delta t}=\phi(\mathbf{b}_t,\mathbf{r}_{t+\Delta t}).
								\label{eq:synchronisingRD}
							\end{equation}
						\end{linenomath*}
						
						Note that the selected NDBC variables as input cannot be synchronised with the attribute to predict.
						
 						For the sake of clarity, considering the matched information shown in Figure \ref{fig:directMatching}a, an example of building a dataset for a \textit{Regression} task is shown in Figure  \ref{fig:regression}a. As mentioned earlier, this prediction task requires a real output variable (in this case, WVHT, the last one). The options considered for the preparation of each final dataset are \mbox{the following}:
 							\begin{itemize}
 								\item Do not synchronise the reanalysis data (see Equation (\ref{eq:noSynchronisingRD}) for the relation between the inputs and the output).
 								\item A prediction horizon of $6$ h.
 							\end{itemize}
							
 						Note that, due to prediction horizon is $6$ h, the values of WVHT attribute are moved backward one instance (up). As a consequence, the last instance (31 December 2017 $18$:$00$) is lost and is not included in the final dataset. In addition, and because the reanalysis data have not been synchronised, the values of the Pres and WSPD variables are at the same time instant ($t$ in Equation (\ref{eq:noSynchronisingRD})).
						
 						Moreover, considering again the matched information shown in Figure \ref{fig:directMatching}a, an example of the creation of the same dataset but applying synchronisation (see Equation (\ref{eq:synchronisingRD})) is shown in Figure  \ref{fig:regression}b.
						
							

						Again, and due to the prediction horizon selected ($6$ h), the values of the WVHT attribute are moved backward one instance (up) and the last instance (31 December 2017 $18$:$00$) is not included in the final dataset. However, now, the values of the Pres variable are also moved backward one instance (due to the synchronisation). Therefore, in this case, Pres is at the same time instant as the attribute to predict (${t+\Delta t}$ in Equation (\ref{eq:synchronisingRD})).
						
						\item \textit{Thresholds of the output attribute} (Classification): Since the values of the variables collected by the buoys are real numbers, it is necessary to discretise them (convert them from real to nominal values) for the attribute selected as output (attribute to be predicted). SPAMDA allows researchers to perform this process by defining the necessary classes with their thresholds, which will be used to carry out such discretisation.
						
						Considering again the matched information shown in Figure \ref{fig:directMatching}a, an example of the creation of a \textit{Classification} dataset is shown in Figure \ref{fig:prediction}. The options considered for the preparation of the final dataset are the following:
%						\newpage
							\begin{itemize}
								\item Do not synchronise the reanalysis data.
								\item A prediction horizon of $6$ h.
								\item The thresholds shown in Table \ref{tab:thresholds}.
							\end{itemize}
%							\vspace{-3pt}

						
						
						
						Note that the attribute to be predicted has been renamed to \textit{Class\_WVHT} to show that it is now a nominal variable because its values have been discretised according to the thresholds (usually defined by an expert). In addition, and due to the $6$ h prediction horizon, the last instance is lost (31 December 2017 $18$:$00$), and the values of the attribute \textit{Class\_WVHT} are moved backward one instance (up). As the reanalysis data have not been synchronised, the values of the Pres and WSPD variables are at the same time instant ($t$ in Equation (\ref{eq:noSynchronisingRD})).
						
					\end{itemize}
				
				The content of the final datasets, obtained as the result of the preparation of the matched data, can be visualised to check everything before saving them on disk. Such preparation can be performed as many times as required and considering the different options in each moment. Although the date will not be included in the final datasets, it can be shown to properly check the matching.
				
				Finally, it is necessary to define the output configuration to create the final datasets:			
				\begin{itemize}

					\item \textit{Output path file}: Name of the final datasets and folder to save them on disk.
						
					\item \textit{Final datasets format}:

						\begin{itemize}
						
							\item \textit{ARFF}: \textit{Attribute-Relation File Format} \cite{WEKA_ARFF}, which is used by WEKA. SPAMDA allows researchers to directly open the final datasets in the Explorer environment of WEKA (in the same context of work), enabling them to choose the most appropriate ML method to tackle the problem under study.

							\item \textit{CSV}: \textit{Comma-Separated Values}. This format is included in order to consider other different tasks of software tools.
							
						\end{itemize}
					
				\end{itemize}
				
				A text file that summarises the configuration used in matching process and in the preparation of the matched data are also generated. It can be saved and loaded, enabling researchers to resume their studies at any other time.
				
    \begin{specialtable}[H]
						
							\caption{Thresholds for the classification example represented in Figure \ref{fig:prediction}.}
							\label{tab:thresholds}
%							\footnotesize
%							\centering
\setlength{\cellWidtha}{\columnwidth/4-2\tabcolsep+0.0in}
\setlength{\cellWidthb}{\columnwidth/4-2\tabcolsep+0.0in}
\setlength{\cellWidthc}{\columnwidth/4-2\tabcolsep+0.0in}
\setlength{\cellWidthd}{\columnwidth/4-2\tabcolsep+0.0in}
\scalebox{1}[1]{\begin{tabularx}{\columnwidth}{>{\PreserveBackslash\centering}m{\cellWidtha}>{\PreserveBackslash\centering}m{\cellWidthb}>{\PreserveBackslash\centering}m{\cellWidthc}>{\PreserveBackslash\centering}m{\cellWidthd}}
\toprule

%							\begin{tabular}{cm{3.20cm}cc@{\setlength{\tabcolsep}{0pt}}m{0.0cm}}
							
							
								
								\textbf{Class}&\textbf{Description}&\textbf{Lower End [}&\textbf{Upper End )}\\
			
									\midrule
								
								Low & Low wave height & $0.36$ & $1.5$\\ \midrule
								
								Average & Average wave height &$1.5$ & $2.5$\\ \midrule
								
								Big & Big wave height & $2.5$ & $4.0$\\ \midrule
								
								Huge & Huge wave height & $4.0$ &$9.9$\\

								\bottomrule
									
							\end{tabularx}}
						
						\end{specialtable}

	\vspace{-10pt}
									
				
				
% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
								\widefigure
								\subfloat[without synchronisation\label{fig:regressionNoSync}]{\includegraphics[width=0.36\textwidth]{figures/FigureRegressionNoSync.png}}\hspace{24pt}
								\subfloat[with synchronisation\label{fig:regressionSync}]{\includegraphics[width=0.36\textwidth]{figures/FigureRegressionSync.png}}\hfill
								\caption{Example of the creation of a \textit{Regression} dataset with a prediction horizon of $6$ h.} \label{fig:regression}
							\end{figure}	
\begin{paracol}{2}
%\linenumbers
\switchcolumn
	
	\vspace{-6pt}
	\begin{figure}[H]
%							\centering
							\includegraphics[scale=0.6]{figures/FigureClassification.png}
							\caption{An example of the creation a \textit{Classification} dataset, with a prediction horizon of $6$ h and without synchronisation.}
							\label{fig:prediction}
						\end{figure}		
				
			\subsection{Manage Reanalysis Data}
				
				As mentioned in Section \ref{sec:DataSources}, the reanalysis data files provided by NNRP contain the estimated values by a mathematical model of one meteorological variable.
				
				In this module (see Figure \ref{fig:SPAMDA}), SPAMDA includes features for entering new files and deleting the unnecessary ones. In addition, useful information about the content of each reanalysis file can be consulted such as name of the file and the reanalysis variable, number of instances and reanalysis nodes, initial and final time, latitude and longitude. All of these fields summarise the temporal and spatial properties of the data. Thus, researchers can quickly and easily identify each reanalysis file entered in SPAMDA.
				
				An example where two reanalysis data files have been entered in SPAMDA is shown in Figure \ref{fig:manageReanalisys}.
				
				\begin{figure}[H]
%					\centering
					\includegraphics[scale=0.45]{figures/FigureManageReanalisys.eps}
					\caption{Example of entering two reanalysis data files.}
					\label{fig:manageReanalisys}
				\end{figure}
				
			\subsection{Tools}
			
				SPAMDA also contains another module that provides two utilities: one of them is \textit{Dataset converter} used for converting the desired intermediate or pre-processed datasets to ARFF or CSV formats; the other utility can be used for opening ARFF files with WEKA Explorer environment, which is useful for easily checking the results of different configurations of the pre-processing.
				
	\section{A Case Study Applied to Gulf of Alaska}\label{sec:CaseStudy}
		
		This section describes how SPAMDA works in a practical approach showing two examples to create fully processed datasets (final datasets) starting from the raw data. The objective of these final datasets is to be used with SC and ML algorithms for environmental modelling, in this case, to classify waves depending on their height and to predict energy flux in the Gulf of Alaska.
		
		On the one hand, wave classification is addressed as a multi-class approach, given that a continuous attribute can be discretised, using different thresholds, in distinct classes. Such wave modelling can be applied with different purposes, such as missing buoy data reconstruction, extreme significant wave heights detection or decision-making and risk assessment about operational works in the sea.

		On the other hand, the prediction of the energy flux is addressed as a regression problem. Energy flux prediction is related to marine energy, and it is useful to characterise the wave energy production from WEC facilities, which could be injected into the electric network or supplied to existing marine platforms.

		\subsection{Gathering the Information and Introducing it in SPAMDA}\label{sec:ObtainingFinalDataset}
		
			The data collected to perform this case study is:
			\begin{enumerate}
			\item The measurements obtained from 2013 to 2017 by the buoy with ID 46001, placed in the Gulf of Alaska, which are provided by NDBC as annual text files. This data are publicly available at the NDBC website. 
			\item Complementary information collected from reanalysis data containing air temperature (air), pressure (pres) and two components of wind speed measurements, South--North (vwind) and West--East (uwind). This information can be downloaded from the NNRP website in NetCDF format for the four closest nodes of reanalysis surrounding the position of the buoy. Concretely, the closest reanalysis nodes downloaded are $57.5$ N $\times$ $147.5$ W, $57.5$ N $\times$ $150$ W, $55$ N $\times$ $147.5$ W, and $55$ N $\times$ $150$ W. However, as will be seen later, only the information from the nearest node will be used in the data integration process.
			\end{enumerate}
		
			After gathering the information described above, researchers can open SPAMDA. In Figure \ref{fig:main_view}, the main view is shown. In order to input the reanalysis data which will be used in further steps for creating the final dataset, researchers has to select the option \textbf{\textit{Manage reanalysis data}}.

			\begin{figure}[H]
%				\centering
				\includegraphics[width=0.55\textwidth]{figures/FigureMain_view.png}
				\caption{SPAMDA main view.}\label{fig:main_view}
			\end{figure}
			
			Then, the view of Figure  \ref{fig:reanalysis} is shown. Here, using the buttons located at the bottom, it is possible to add, delete, or consult any data from the different reanalysis files. Once the information has been introduced in the application, this view can be closed and the user can go back to the main view to continue entering the information related to the buoy under study. 
\newpage			
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.89\textwidth]{figures/FigureManage_reanalysis_data.png}
				\caption{\textit{Manage reanalysis data} view: downloaded files containing the four closest reanalysis nodes.}\label{fig:reanalysis}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn



			
			After that, the researcher has to select \textbf{\textit{Manage buoys data}} to open the view shown in Figure \ref{fig:manage_buoys}, where several tabs are available. In the \textbf{\textit{Buoys}} tab, the researcher can consult, modify, add, or delete different data related to the buoy.
			
					
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.89\textwidth]{figures/FigureManage_buoys.png}
				\caption{\textit{Buoys} tab: buoy ID 46001.}\label{fig:manage_buoys}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn
			
			In order to enter such data, click on the \textbf{\textit{New}} button, and then the view shown in Figure \ref{fig:new_buoy} pops up.

			\begin{figure}[H]
%				\centering
				\includegraphics[width=0.65\textwidth]{figures/FigureNew_buoy.png}
				\caption{\textit{New buoy} view: information of the buoy ID 46001.}\label{fig:new_buoy}
			\end{figure}
			
			Here, the information about the buoy has to be included: the \textit{Station ID}, its description, geographical localisation, and the corresponding annual text files. In this case, the files containing the data from year $2013$ to $2017$ are inserted by clicking on the \textbf{\textit{Add file}} button. Once the data have been introduced, it is necessary to click on the \textbf{\textit{Save}} button to insert the buoy in SPAMDA database. After that, the view can be closed.  
		
			
			
			To create the intermediate dataset, the researcher has to double-click on the buoy under study or click on the \textbf{\textit{Datasets}} tab (see Figure \ref{fig:manage_buoys}) to switch to the corresponding view (see Figure \ref{fig:show_datasets}). In this view, the researcher can delete or consult a summary of each intermediate or pre-processed dataset by selecting it from the corresponding list. It can also create new ones. To proceed with the creation of the intermediate dataset, the user clicks on the \textbf{\textit{New}} button, and the view shown in Figure \ref{fig:intermediate} appears. 
			
			
			
			Here, the researcher can select the annual text files to be included in the intermediate dataset, by clicking on the \textbf{\textit{->}} and \textbf{\textit{<-}} buttons. In this case, all the files introduced before, which correspond to the buoy under study, are selected. When the file selection is finished, \textbf{\textit{Create}} button has to be clicked in order to introduce the description and the file name of the current intermediate dataset, and, then, with the \textbf{\textit{Save}} button, the creation process starts, showing the status of the process during it. After that, in order to prepare the intermediate dataset, the dataset is selected (see Figure \ref{fig:show_datasets}), and then the button \textbf{\textit{Open}} is clicked to jump to the tab \textbf{\textit{Pre-process}} (shown in Figure \ref{fig:preprocess_data}).
			
			In \textbf{\textit{Pre-process}} tab, relevant statistical information about the selected dataset is shown, and also the content of the dataset can be consulted, providing the researcher the capacity to evaluate the pre-processing being performed. Here, the researcher can apply (and configure) the necessary filters (explained in Section \ref{sec:Preprocess}) to the selected dataset, and, in the bottom part, the main statistics of the dataset are displayed, which can be used to observe the changes produced when applying a filter. As mentioned earlier, this case study is focused on classifying waves considering their height, so any missing data from wave height ($376$~values) and the remaining attributes are recovered, using the filter \textit{Replace missing values with symmetric $3$ h mean}. Furthermore, the attributes MWD, DEWP, VIS and TIDE are removed from the dataset by applying the filter \textit{RemoveByName}, since the first two had more than $92$\% of missing data and the last two $100$\%. After finishing the pre-processing of the dataset, the researcher can click on the \textbf{\textit{Save}} button, to introduce the description and file name for the current pre-processed dataset.
			
			At this point, the researcher has registered the buoy in SPAMDA, then entered its raw data and selected the required data for the problem (intermediate dataset). Finally, the data have been pre-processed in order to be ready for its future use in ML algorithms. Then, a data integration process can be carried out to merge the processed data from NDBC with the reanalysis data (also included previously) from NNRP.
			
			
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.85\textwidth]{figures/FigureDatasets.png}
				\caption{\textit{Datasets} tab: intermediate datasets of the buoy ID 46001.}\label{fig:show_datasets}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn	
\vspace{-6pt}
		
			\begin{figure}[H]
%				\centering
				\includegraphics[width=0.67\textwidth]{figures/FigureNew_intermediate_dataset.png}
				\caption{\textit{New intermediate dataset} view: creating the intermediate dataset with five annual text files.}\label{fig:intermediate}
			\end{figure}
\vspace{-6pt}

		\newpage	
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.90\textwidth]{figures/FigurePreprocess.png}
				\caption{\textit{Pre-process} tab: pre-processing the created intermediate dataset.}\label{fig:preprocess_data}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn

			
			
			The next step is to customise (or load) the parameters of the matching process according to the problem being studied and to select the prediction task (described in \mbox{Section \ref{sec:matching_conf}}) that the final dataset will be used for, in this case, waves classification or energy flux prediction.
			
			\subsection{Waves Classification}
			
			As mentioned above, the objective of the final dataset is to be used with SC and ML algorithms to classify waves depending on their significant height. The following sections describe the procedure of performing the data integration provided by SPAMDA, modelling wave height by using classification algorithms available in WEKA.
			
			\subsubsection{Obtaining the Final Dataset}
			
			By clicking on the \textbf{\textit{Matching configuration}} tab, the view shown in Figure \ref{fig:matching_conf_wc} will be opened. In this view, the researcher can configure the parameters of the data integration process. For this problem, the following parameters were selected:
			\begin{itemize}
				\item Attribute to predict: WVHT.
				\item Reanalysis data: Air, pressure, u-wind and v-wind.
				\item Buoy attributes to be used as inputs: WDIR, WSPD, GST, DPD, APD, PRES, ATMP and WTMP (see Table \ref{tab:measurementsDescription} or descriptions of the measurements in the NDBC website).
				\item Reanalysis nodes to consider: $1$ (only the closest reanalysis node will be used).
				\item Number of final datasets: In this example, that option is disabled because only one reanalysis node is considered.
				\item Prediction task: Classification.
			\end{itemize} 
			
			
			
			After configuring the matching process, the researcher can click on the \textbf{\textit{Run}} button to jump to the view shown in Figure \ref{fig:final_dataset} and proceed to define the final dataset structure according to the selected prediction task. Given that, in the previous view (Figure \ref{fig:matching_conf_wc}), \textit{Classification} was selected, the researcher can now add, modify, or delete the thresholds (usually defined by an expert) for discretising the output variable (top left of Figure \ref{fig:final_dataset}). After this, the next step is to set the time horizon desired (6 h by default) and also to activate (if desired) the synchronisation (in time) of reanalysis variables with the output (top right of Figure \ref{fig:final_dataset}), as explained in Section {\ref{sec:FinalDatasets}}. Then, the researcher can click on the \textbf{\textit{Update final dataset}} button to see the content shown in the bottom left corner (NDBC observations, NNRP variables, missing values, dates). Finally, after checking that everything is correct, the last step would be to select the name and path of the dataset file, and its output format (CSV or ARFF) and click on the \textbf{\textit{Create final datasets}} button (bottom right of Figure  \ref{fig:final_dataset}). For this example, the following configuration was applied:
			\begin{itemize}
				\item Thresholds: see Table \ref{tab:thresholds}.
				\item Prediction horizon: 6 h.
				\item Synchronisation: Disabled.
				\item Final dataset format: ARFF.
			\end{itemize}
			
			At this point, the final dataset would be created according to the tailored configuration and stored in the computer of the researcher, which already can apply the ML techniques to address the problem of wave classification. Concretely, the final dataset consists of \mbox{$7302$ instances} and whose distribution is represented in Table \ref{tab:datasetDistribution}.
			
			
			
			
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.90\textwidth]{figures/FigureMatching_configuration.png}
				\caption{\textit{Matching configuration} tab: parameters for the data integration of the intermediate dataset and the reanalysis files (waves classification).}\label{fig:matching_conf_wc}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn
\vspace{-6pt}

	
			
			%
		    \begin{specialtable}[H]
					\caption{Distribution of instances of the final dataset.}
					\label{tab:datasetDistribution}
					\setlength{\cellWidtha}{\columnwidth/2-2\tabcolsep+0.0in}
\setlength{\cellWidthb}{\columnwidth/2-2\tabcolsep+0.0in}
\scalebox{1}[1]{\begin{tabularx}{\columnwidth}{>{\PreserveBackslash\centering}m{\cellWidtha}>{\PreserveBackslash\centering}m{\cellWidthb}}
\toprule
						\textbf{Year}&\textbf{Number of Instances}\\
						\midrule
						$2013$&$1460$\\
						$2014$&$1460$\\
						$2015$&$1460$\\
						$2016$&$1464$\\
						$2017$&$1458$\\
						\midrule
						&$7302$\\
						\bottomrule
					\end{tabularx}}
				\end{specialtable}
			\vspace{-6pt}	
			
				\newpage	
				% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\centering
				\includegraphics[width=0.90\textwidth]{figures/FigureFinal_datasets.png}
				\caption{\textit{Final datasets} tab: content of the final dataset created after data integration and discretisation of the output variable in four~classes.}\label{fig:final_dataset}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn
\vspace{-12pt}

		%
		\subsubsection{Obtaining Classification Models with ML Algorithms}
		
			Now, the process to obtain wave classification models is described using the final dataset previously created with SPAMDA. The modelling will be performed using WEKA as SC and ML tool, which can be opened through SPAMDA, as shown in Figure \ref{fig:openigFinalDatasetWeka}. Nevertheless, as mentioned above, the researcher can create the final dataset in CSV format in order to use any other ML tools, such as KEEL, Python, or R, among others.
			
			
			
			Since the final dataset is a time series of meteorological data (collected from $2013$ to $2017$), a hold-out scheme (60\% train/40\% test) will be used. In this way, years from $2013$ to $2015$ will be used for the training phase ($4380$ instances), whereas $2016$ and $2017$ years will be used for the test phase ($2922$ instances). Previous to the learning phase, the attributes are normalised to avoid some attributes dominating others because of a larger scale.
			
			The classification algorithms that will be considered for wave modelling are Logistic Regression \cite{hosmer2013applied}, C4.5 \cite{quinlan2014c4}, Random Forest \cite{breiman2001random}, Support Vector Machine \cite{cortes1995support} and Multilayer Perceptron \cite{haykin1994neural}, which will be applied with the default values of the parameters provided by WEKA. Given that Logistic Regression and C4.5 algorithms are deterministic, only one run will be considered for each one. However, Random Forest, Support Vector Machine and Multilayer Perceptron algorithms have a stochastic component, so, in this case, 30 executions for each one will be carried out. Table \ref{tab:results} shows the results of \mbox{this experimentation}.
			
				
				
			As can be seen, Random Forest and Multilayer Perceptron algorithms have achieved similar accuracy, but the performance of the latter is slightly better. Although this is an illustrative classification example using datasets built with SPAMDA, both models have obtained good performance, despite the fact that the problem being tackled is difficult (prediction is approached six hours in advance).
			
			% start a new page without indent 4.6cm
\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.95\textwidth]{figures/FigureOpeningFinalDatasetWeka.png}
				\caption{Final dataset opened with the environment Explorer of WEKA (waves classification).}
				\label{fig:openigFinalDatasetWeka}
			\end{figure}
			\vspace{-6pt}

\begin{paracol}{2}
%\linenumbers
\switchcolumn
   \begin{specialtable}[H]
				
					\caption{Results (mean $\pm$ SD) obtained by the algorithms.}
					\label{tab:results}
					\setlength{\cellWidtha}{\columnwidth/3-2\tabcolsep+0.0in}
\setlength{\cellWidthb}{\columnwidth/3-2\tabcolsep+0.0in}
\setlength{\cellWidthc}{\columnwidth/3-2\tabcolsep+0.0in}
\scalebox{1}[1]{\begin{tabularx}{\columnwidth}{>{\PreserveBackslash\centering}m{\cellWidtha}>{\PreserveBackslash\centering}m{\cellWidthb}>{\PreserveBackslash\centering}m{\cellWidthc}}
\toprule
						
						\textbf{Algorithm}&\textbf{Accuracy (CCR)}&\textbf{Kappa}\\
	
						\midrule
						
						Logistic Regression & $59.0691$ & $0.44447$\\ 		\midrule
						
						C4.5 & $61.7385$ & $0.47852$\\ 		\midrule
						
						Random Forest & $68.6516 \pm 0.3083$ & $0.57040 \pm 0.0042$\\ 		\midrule
						
						Support Vector Machine & $61.0016 \pm 0.0522$ & $0.46770 \pm 0.0007$\\ 		\midrule
						
						Multilayer Perceptron & $69.7045 \pm 1.3033$  & $0.58576 \pm 0.0178$\\ 	

						\bottomrule
							
					\end{tabularx}}
				
				\end{specialtable}			
			\subsection{Energy Flux Prediction}
			
			As mentioned above, the final dataset of this example is also used with SC and ML algorithms to predict flux of energy. The following sections explain the process of performing the data integration provided by SPAMDA to build the final dataset, modelling the flux of energy by using regression algorithms available in WEKA.
			
			\subsubsection{Obtaining the Final Dataset}
			
			The researcher can configure the parameters of the data integration by clicking on the \textbf{\textit{Matching configuration}} tab. For this problem, as shown in Figure \ref{fig:matching_conf_ef}, the following parameters were selected:
			\begin{itemize}
				\item Attribute to predict: Flux of energy.
				\item Reanalysis data: Air, pressure, u-wind and v-wind.
				\item Buoy attributes to be used as inputs: WDIR, WSPD, GST, DPD, APD, PRES, ATMP and WTMP (see Table \ref{tab:measurementsDescription} or descriptions of the measurements in the NDBC website).
				\item Reanalysis nodes to consider: $1$ (only the closest reanalysis node will be used).
				\item Number of final datasets: In this example, this option is disabled because only one reanalysis node is considered.
				\item Prediction task: Regression.
			\end{itemize} 
			
			After configuring the parameters of the matching process, the next step is to define the final dataset structure according to the selected prediction task. Researchers can click on the \textbf{\textit{Run}} button to jump to the view shown in Figure \ref{fig:final_dataset_EF}. Note that the thresholds for discretising the output variable (top left of  Figure \ref{fig:final_dataset_EF}) are disabled due to, in this case, energy flux prediction being a regression problem.
			
			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.85\textwidth]{figures/FigureMatching_configuration_EF.png}
				\caption{\textit{Matching configuration} tab: parameters for the data integration of the intermediate dataset and the reanalysis files (energy flux prediction).}\label{fig:matching_conf_ef}
			\end{figure}
\vspace{-6pt}

\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.85\textwidth]{figures/FigureFinal_datasets_EF.png}
				\caption{\textit{Final datasets} tab: content of the final dataset created after data integration.}\label{fig:final_dataset_EF}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn


			By default, the time horizon is set to six hours, that is, the energy flux prediction will be performed six hours in advance (top right of Figure \ref{fig:final_dataset_EF}), but researchers can increase such time horizon depending on their needs. The synchronisation (in time) of reanalysis variables with the output (explained in Section {\ref{sec:FinalDatasets}}) can be set in this view. By clicking on the \textbf{\textit{Update final dataset}} button, researchers can preview the content of the final dataset (bottom left corner of  Figure  \ref{fig:final_dataset_EF}). Finally, the last step would be to set the name, path and output format (CSV or ARFF) of the dataset file, and then the user should click on the \textbf{\textit{Create final datasets}} button (bottom right of  Figure  \ref{fig:final_dataset_EF}). For this example, the following configuration was applied:
			\begin{itemize}
				\item Prediction horizon: 6 h.
				\item Synchronisation: Disabled.
				\item Final dataset format: ARFF.
			\end{itemize}
			
			After that, the final dataset would be created and stored in the computer of the researcher according to the introduced configuration, ready to be used as input for SC and ML techniques to tackle the problem of energy flux prediction. The number of instances ($7302$) and the distribution of the final dataset (Table \ref{tab:datasetDistribution}) are the same as in the previous example (waves classification) since the data used to create the final dataset and the time horizon selected (6 h) are the same.

		\subsubsection{Obtaining Prediction Models with ML Algorithms}

			In this example, WEKA is used as SC and ML tool to obtain energy flux prediction models, as shown in Figure \ref{fig:openigFinalDatasetWeka_EF}. Nonetheless, the final dataset can be created in CSV format so that the researcher can use any other SC and ML tool.

			% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
				\widefigure
				\includegraphics[width=0.95\textwidth]{figures/FigureOpeningFinalDatasetWeka_EF.png}
				\caption{Final dataset opened with the environment Explorer of WEKA (energy flux prediction).}
				\label{fig:openigFinalDatasetWeka_EF}
			\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn

			
			For this problem, the same partitioning scheme used in the wave classification problem is considered (60\% train/40\% test), that is, from $2013$ to $2015$ for the training phase ($4380$ instances) and $2016$ and $2017$ for the test phase ($2922$ instances). Again, the attributes are normalised prior to the learning phase.
			
			To perform the energy flux modelling, one execution will be run for the deterministic algorithm Linear Regression \cite{Bishop:2006:PRM:1162264}, whereas $30$ executions will be considered for the stochastic ones: Random Forest \cite{breiman2001random}, Support Vector Machine \cite{cortes1995support} and Multilayer Perceptron \cite{haykin1994neural}. Table \ref{tab:results_EF} shows the experimental results obtained using the default values for the parameters of the algorithms provided by WEKA.

				 \begin{specialtable}[H]
				
					\caption{Results (mean $\pm$ SD) obtained by the algorithms.}
					\label{tab:results_EF}
%					\footnotesize
%					\centering

					\setlength{\cellWidtha}{\columnwidth/3-2\tabcolsep+0.0in}
\setlength{\cellWidthb}{\columnwidth/3-2\tabcolsep+0.0in}
\setlength{\cellWidthc}{\columnwidth/3-2\tabcolsep+0.0in}
\scalebox{1}[1]{\begin{tabularx}{\columnwidth}{>{\PreserveBackslash\centering}m{\cellWidtha}>{\PreserveBackslash\centering}m{\cellWidthb}>{\PreserveBackslash\centering}m{\cellWidthc}}
\toprule
						
						\textbf{Algorithm}&\textbf{Root Mean Squared Error}&\textbf{Correlation Coefficient}\\
	
						\midrule
						
						Linear Regression & $29.6368$ & $0.7296$\\ 		\midrule
						
						Random Forest & $23.4353 \pm 0.1313$ & $0.8408 \pm 0.0021$\\ 		\midrule
						
						Support Vector Machine & $31.3008 \pm 0.1197$ & $0.7275 \pm 0.0015$\\ 		\midrule
						
						Multilayer Perceptron & $27.1151 \pm 7.5536$ & $0.8444 \pm 0.0193$\\

						\bottomrule
							
					\end{tabularx}}
				
				\end{specialtable}
			
			As can be checked, Random Forest has achieved the best performance for the Root mean squared error. The standard deviation of the results obtained by Multilayer Perceptron indicates that this algorithm may have been slightly affected by its stochastic component. However, both Multilayer Perceptron and Random Forest have obtained an excellent Correlation coefficient.
			
			In this case study, the use of datasets created with SPAMDA has been shown to address an energy flux prediction problem. An exhaustive comparison of regression algorithms is not the purpose of this work. However, note that Multilayer Perceptron and Random Forest algorithms have achieved very good results despite the fact that the energy flux prediction has been performed with a time horizon of 6 h.

		\subsection{Important Remarks}
		
			In this section, it has been described how to use SPAMDA to create final datasets with the aim of classifying waves and predicting flux of energy. However, using the same data described in Section \ref{sec:ObtainingFinalDataset}, the researcher can quickly address other objectives or different studies by merely tailoring the matching configuration of the data integration process. For example, longer-term wave or energy flux prediction can be addressed by changing the time horizon, waves modelling can be approached from another perspective by creating the final dataset for regression, or environmental modelling can be focused in diverse fields by changing the output meteorological variable.

			Furthermore, environmental modelling in other geographical location can be carried out by merely using other collected data.
			
			As SPAMDA performs all data processing and management to create the datasets, it not only prevents researchers from performing repetitive tasks but also prevents them from making possible errors. In this way, researchers can focus on the studies they are carrying~out.
		
	\section{Conclusions}\label{sec:Conclusions}

		%A new open source tool named SPAMDA with a user-friendly GUI for creating datasets using meteorological data from NDBC and NNRP has been presented in this work. The aim of the tool presented in this work is to provide the research community with an automated, customisable and robust integration for NDBC and NNRP data, serving as a tool for analysis and decision support in marine energy and engineering applications, among others.
		
		%Studies on marine energy using ML and SC methodologies apply specific algorithms (extreme learning machine, metaheuristics, Bayesian networks, neural networks, etc) on data using custom-made implementations or scripts developed in some programming language; but they do not allow for build datasets in an automated way ready to be used as input for prediction tasks (classification or regression). These datasets can be easily obtained with SPAMDA by means of the selection of different input parameters, such as predictive and objective variables, output discretisation or prediction horizon. As a result, researchers will benefit from significant support when carrying out environmental modelling related to energy, atmospheric or oceanic studies, among others. Moreover, given that SPAMDA simplifies all the intermediate steps involved in the creation of datasets and manages the extensive casuistry of the data integration (such as entering the meteorological information, managing with the incomplete data, pre-processing tasks, the customisable matching process to merge the data and the preparation of the datasets according to the SC or ML technique to use), it avoids errors and reduces the time needed. In this way, researchers will be able to have more in-depth analysis, which could result in more complete conclusions about the issue under study.
		
{Studies on marine energy using ML and SC methodologies apply specific algorithms (extreme learning machine, metaheuristics, Bayesian networks, neural networks, etc.) on data using custom-made implementations or scripts developed in some programming language; but they do not allow for building datasets in an automated way ready to be used as input for prediction tasks (classification or regression). In this sense, a new open source tool named SPAMDA has been presented in this work, with a user-friendly GUI for creating datasets using meteorological data from NDBC and NNRP. The aim of the tool is to provide the research community with an automated, customisable and robust integration for NDBC and NNRP data, serving as a tool for analysis and decision support in marine energy and engineering applications, among others.}
		
		Such datasets can be easily obtained with SPAMDA by means of the selection of different input parameters, such as predictive and objective variables, output discretisation or prediction horizon. As a result, researchers will benefit from significant support when carrying out environmental modelling related to energy, atmospheric or oceanic studies, among others. Moreover, given that SPAMDA simplifies all the intermediate steps involved in the creation of datasets and manages the extensive casuistry of the data integration (such as specifying the meteorological information, managing incomplete data, pre-processing tasks, the customisable matching process to merge the data and the preparation of the datasets according to the SC or ML technique to use), it avoids errors and reduces the time needed. In this way, researchers will be able to have more in-depth analysis, which could result in more complete conclusions about the issue under study.
		
		The case study described in Section \ref{sec:CaseStudy} illustrates how SPAMDA can be used by researchers in a practical approach for environmental modelling, concretely, to classify waves in the Gulf of Alaska depending on their height. The case study also covers an example of energy flux prediction, to predict the wave energy that could be exploited by WEC facilities six hours in advance, although such time horizon is customisable. Given that this work does not focus on models performance, a more extensive validation or comparison study of the results obtained in both examples has not been carried out. {The final datasets obtained with SPAMDA can be replicated by researchers using the same meteorological data from NDBC and NNRP (publicly available) and applying the same parameters for the pre-processing tasks and the data integration process. After that, the models and results obtained, using such final datasets, will depend on the SC or ML tool used.}

		In order to improve SPAMDA, some future work could be focused on new functional modules for managing meteorological data of different formats \cite{NOAA_3}, so that the developed tool can be extended to any other research, new pre-processing functionalities such as filters to analyse the correlation between attributes or new functional modules for recovering missing values using nearby buoys data \cite{DuranRosal2016}. Furthermore, the developed software could manage other sources of reanalysis data (with different spatial and temporal resolution), and new output formats for the datasets which could be used as input by other tools for ML such as KEEL (\textit{Knowledge Extraction based on Evolutionary Learning}) \cite{AlcalFdez2009KEELAS}. However, such new functionalities can be developed with a reasonable effort to be able to manage each particular casuistry. For example, when dealing with incomplete data, interpreting different data and files structures or carrying out the matching process of two environmental data sources.

%    \section*{Additional material}
%	
%		The source code and the software tool are available at \url{https://github.com/ayrna}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\supplementary{The source code and the software tool are available at \url{https://github.com/ayrna}.}

% Only for the journal Methods and Protocols:
% If you wish to submit a video article, please do so with any other supplementary material.
% \supplementary{The following are available at \linksupplementary{s1}, Figure S1: title, Table S1: title, Video S1: title. A supporting video article is available at doi: link.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used ``Conceptualization, X.X. and Y.Y.; methodology, X.X.; software, X.X.; validation, X.X., Y.Y. and Z.Z.; formal analysis, X.X.; investigation, X.X.; resources, X.X.; data curation, X.X.; writing--original draft preparation, X.X.; writing--review and editing, X.X.; visualization, X.X.; supervision, X.X.; project administration, X.X.; funding acquisition, Y.Y. All authors have read and agreed to the published version of the manuscript.'', please turn to the  \href{http://img.mdpi.org/data/contributor-role-instruction.pdf}{CRediT taxonomy} for the term explanation. Authorship must be limited to those who have contributed substantially to the work reported.}

\authorcontributions{Conceptualization, Formal analysis and Investigation, A.M.G.-O., J.C.F., M.D.-M., P.A.G. and C.H.-M.; Funding acquisition, Project administration, Resources and Supervision, P.A.G. and C.H.-M.; Methodology, A.M.G.-O., J.C.F., M.D.-M., P.A.G. and C.H.-M.; Software, \mbox{A.M.G.-O.}, J.C.F. and M.D.-M.; Validation, A.M.G.-O., J.C.F., M.D.-M., P.A.G. and C.H.-M.; Writing---original draft, A.M.G.-O., J.C.F. and M.D.-M. All authors have read and agreed to the published version of the manuscript.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\funding{Please add: ``This research received no external funding'' or ``This research was funded by NAME OF FUNDER Grant No.  XXX.'' and  and ``The APC was funded by XXX''. Check carefully that the details given are accurate and use the standard spelling of funding agency names at \url{https://search.crossref.org/funding}, any errors may affect your future funding.}

%\funding{This work has been partially subsidised by the projects with references TIN2017-85887-C2-1-P of the Spanish Ministry of Economy and Competitiveness (MI\-NE\-CO), UCO-1261651 of the ``Consejer\'ia de Econom\'ia, Conocimiento, Empresas y Universidad'' of the ``Junta de Andaluc\'ia'' (Spain) and FEDER funds of the European Union. We also thank to NVIDIA Corporation for the transfer of computational resources for research works.}

\funding{This work has been partially subsidised by the projects with references TIN2017-85887-C2-1-P of the Spanish Ministry of Economy and Competitiveness (MI\-NE\-CO), UCO-1261651 of the ``Consejer\'ia de Econom\'ia, Conocimiento, Empresas y Universidad'' of the ``Junta de Andaluc\'ia'' (Spain) and FEDER funds of the European Union.}
\institutionalreview{Not applicable.}%MDPI: In this section, you should add the Institutional Review Board Statement and approval number, if relevant to your study. You might choose to exclude this statement if the study did not require ethical approval. Please note that the Editorial Office might ask you for further information. Please add ``The study was conducted according to the guidelines of the Declaration of Helsinki, and approved by the Institutional Review Board (or Ethics Committee) of NAME OF INSTITUTE (protocol code XXX and date of approval).'' OR ``Ethical review and approval were waived for this study, due to REASON (please provide a detailed justification).'' OR ``Not applicable'' for studies not involving humans or animals.}

\informedconsent{Not applicable.}%MDPI: Please add ``Informed consent was obtained from all subjects involved in the study.'' OR ``Patient consent was waived due to REASON (please provide a detailed justification).'' OR ``Not applicable'' for studies not involving humans.}

\dataavailability{Publicly available datasets were analyzed in this study. This data can be found in the National Data Buoy Center (NDBC) and the NOAA Physical Sciences Laboratory (PSL).}%MDPI: Please refer to suggested Data Availability Statements in section “MDPI Research Data Policies” at \href{https://www.mdpi.com/ethics}{https://www.mdpi.com/ethics}}. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\acknowledgments{In this section you can acknowledge any support given which is not covered by the author contribution or funding sections. This may include administrative and technical support, or donations in kind (e.g., materials used for experiments).}

\acknowledgments{The authors also thank NOAA/OAR/ESRL PSD, Boulder, CO, USA for the NCEP Reanalysis data provided from their Web site at \url{https://www.esrl.noaa.gov/psd/}, to NOAA/NDBC by its data that were collected and made freely available, to the University of Waikato for the WEKA (Waikato Environment for Knowledge Analysis) software tool, to University Corporation for Atmospheric Research/Unidata for the NetCDF (network Common Data Form) Java library and to QOS.ch for the SLF4J (Simple Logging Facade for Java) library.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\conflictsofinterest{Declare conflicts of interest or state ``The authors declare no conflict of interest.'' Authors must identify and declare any personal circumstances or interest that may be perceived as inappropriately influencing the representation or interpretation of reported research results. Any role of the funders in the design of the study; in the collection, analyses or interpretation of data; in the writing of the manuscript, or in the decision to publish the results must be declared in this section. If there is no role, please state ``The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results''.} 

%\conflictsofinterest{The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results.} 

\conflictsofinterest{The authors declare no conflict of interest.} 
%\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\abbreviations{The following abbreviations are used in this manuscript:\\
\abbreviations{Abbreviations used in this manuscript:\\

% \noindent 
% \begin{tabular}{@{}ll}
% MDPI & Multidisciplinary Digital Publishing Institute\\
% DOAJ & Directory of open access journals\\
% TLA & Three letter acronym\\
% LD & linear dichroism
% \end{tabular}}

\noindent 
\begin{tabular}{@{}ll}
$F_e$ & Flux of energy\\
$H_s$ & Significant wave height\\
$T_e$ & Wave energy period\\
$p_0$ & Geographical location of the buoy\\
$p_j$ & Geographical location of each reanalysis node\\
$lat$ & Latitude of the point\\
$lon$ & Longitude of the point\\
$o_{t}$ & The attribute to be predicted at the time instant to study\\
$\Delta t$ & The prediction horizon\\
$\mathbf{b}_t$ & The vector containing the selected NDBC variables\\
$\mathbf{r}_{t}$ & The vector containing the selected reanalysis variables\\
\end{tabular}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\appendixtitles{no} % Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
\appendixtitles{yes}
\appendixstart
\appendix
\section{Managing the Casuistry of Incomplete Data}\label{app:AppendixA}

		In this appendix, we describe how SPAMDA deals with incomplete data when creating intermediate datasets and performing the matching process.
		
		The measurements collected by the buoys may be incomplete or recorded at a different time than the expected one, due to the weather conditions in which the buoys have to operate. To illustrate this casuistry, the following examples are shown in Figure \ref{fig:measurements}:		
		\begin{itemize}
			\item In the instance marked with (a), the measurement of $17$:$50$ was collected at $17$:$45$, \mbox{$5$ min} earlier.
			\item In the instance marked with (b), the measurement of $23$:$50$ was collected at $23$:$30$, \mbox{$20$ min} earlier.
			\item In the instance marked with (c), the measurement of $05$:$50$ is duplicated.
			\item In the instance marked with (d), the measurement of $11$:$50$ is missing (missing date or instance).
			\item In the instance marked with (e), the measurement of $17$:$50$ and $18$:$50$ are missing (missing dates or instances).
			\item Missing values highlighted in red.
		\end{itemize}
		

		
		SPAMDA has been designed to tackle these situations, and it informs researchers of any incidence found while reading the annual text files for creating the intermediate datasets. For the case of measurements that were recorded at a different time than expected, a time gap of 6 min ($10\%$ of an hour) has been established. Therefore, if the time difference exceeds such value, the date will be considered as an unexpected.
		
		Figure \ref{fig:creatingDataset} shows the status of the creation of an intermediate dataset with the information of Figure \ref{fig:measurements}. Note that the instance marked with a) has not been informed by SPAMDA as an unexpected date because its time difference is less than six minutes. Depending on the affected attribute, NDBC uses a specific value \cite{NOAA_3} to indicate the presence of lost data (e.g., $99$ for VIS and TIDE attributes, $999$ for DEWP, MWD and WDIR, etc.). SPAMDA interprets these specific values and, after creating the intermediate dataset, researchers can check if it contains missing values by visualising its statistical information or content. Remember that SPAMDA provides several filters for recovering missing data, which were described in Section \ref{sec:Datasets}.
		
		SPAMDA takes into account this casuistry when carrying out the matching process. An example is given in Figure \ref{fig:matchingMeasurements}. As mentioned above, the matching process is performed with the nearest measurement (previous or next) within a maximum of 60 min of difference. However, in the instance marked with $e)$, given that the measurements dates 1 May 2017 $17$:$50$ and 1 May 2017 $18$:$50$ are missing, the reanalysis date 1 May 2017 $18$:$00$ cannot be matched with buoy data (this date is highlighted in mauve in Figure \ref{fig:matchingMeasurements}). Depending on the selection made by researchers in the parameter \textit{Include missing dates}, this instance will be included in the final dataset (with missing values for buoy variables) or not.
		
	% start a new page without indent 4.6cm
%\clearpage
\end{paracol}
\nointerlineskip
\appendix
\begin{figure}[H]
	\widefigure
			\includegraphics[scale=0.55]{figures/FigureMeasurements.png}
			\caption{A fragment of an annual text file with different missing value examples.}
			%Figures A1 and A3, 1. Please fill in the brackets parentheses of Numbering subfigure. 2. Please add explanation of subfigure (a)--(e). 3. Please add explanation of different colors. AUTHORS: the explanation is in the maintext
			\label{fig:measurements}
		\end{figure}	
\begin{paracol}{2}
%\linenumbers
\switchcolumn
		\vspace{-6pt}
		
		\begin{figure}[H]
%			\centering
			\includegraphics[scale=0.6]{figures/FigureCreatingDataset.png}
			\caption{Status of the creation of the intermediate dataset for the example of Figure \ref{fig:measurements}.}
			\label{fig:creatingDataset}
		\end{figure}
		\vspace{-6pt}
		
		
		% start a new page without indent 4.6cm
\clearpage
\end{paracol}
\nointerlineskip
\begin{figure}[H]
			\widefigure
			\includegraphics[scale=0.45]{figures/FigureMatchingMeasurements.png}
			\caption{Matching the measurements (\textbf{left}) and the reanalysis data (\textbf{right}).}
			\label{fig:matchingMeasurements}
		\end{figure}
\begin{paracol}{2}
%\linenumbers
\switchcolumn

		
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{paracol}
\reftitle{References}


% Please provide either the correct journal abbreviation (e.g., according to the “List of Title Word Abbreviations” http://www.issn.org/services/online-services/access-to-the-ltwa/) or the full name of the journal.
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 

%=====================================
% References, variant A: external bibliography
%=====================================
%\externalbibliography{yes}
%\bibliography{your_external_BibTeX_file}
%\externalbibliography{yes}
%\bibliography{bibfile}
\begin{thebibliography}{999}

\bibitem[Anis \em{et~al.}(2019)Anis, Jamil, Ansari, and
  Bellos]{SHAHRUKHANIS2019179}
Anis, M.S.; Jamil, B.; Ansari, M.A.; Bellos, E.
\newblock {Generalized models for estimation of global solar radiation based on
  sunshine duration and detailed comparison with the existing: A case study for
  India}.
\newblock {\em Sustain. Energy Technol. Assess.} {\bf 2019},
  {\em 31},~179--198, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.seta.2018.12.009}{\detokenize{10.1016/j.seta.2018.12.009}}}.

\bibitem[Laface \em{et~al.}(2015)Laface, Arena, and Soares]{LAFACE201545}
Laface, V.; Arena, F.; Soares, C.G.
\newblock {\textls[-15]{Directional analysis of sea storms}}.
\newblock {\em Ocean Eng.} {\bf 2015}, {\em 107},~45--53, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.oceaneng.2015.07.027}{\detokenize{10.1016/j.oceaneng.2015.07.027}}}.

\bibitem[Shivam \em{et~al.}(2020)Shivam, Tzou, and Wu]{Kumar2020}
Shivam, K.; Tzou, J.C.; Wu, S.C.
\newblock Multi-Objective Sizing Optimization of a Grid-Connected Solar–Wind
  Hybrid System Using Climate Classification: A Case Study of Four Locations in
  Southern Taiwan.
\newblock {\em Energies} {\bf 2020}, {\em 13},~2505, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en13102505}{\detokenize{10.3390/en13102505}}}.

\bibitem[Dorado-Moreno \em{et~al.}(2017)Dorado-Moreno, Cornejo-Bueno,
  Guti{\'e}rrez, Prieto, Herv{\'a}s-Mart{\'i}nez, and
  Salcedo-Sanz]{DORADOMORENO2017428}
Dorado-Moreno, M.; Cornejo-Bueno, L.; Guti{\'e}rrez, P.A.; Prieto, L.;
  Herv{\'a}s-Mart{\'i}nez, C.; Salcedo-Sanz, S.
\newblock {Robust estimation of wind power ramp events with reservoir
  computing}.
\newblock {\em Renew. Energy} {\bf 2017}, {\em 111},~428--437, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.renene.2017.04.016}{\detokenize{10.1016/j.renene.2017.04.016}}}.

\bibitem[He \em{et~al.}(2020)He, Zha, Song, Hao, Du, Liotta, and Perra]{He2020}
He, Q.; Zha, C.; Song, W.; Hao, Z.; Du, Y.; Liotta, A.; Perra, C.
\newblock Improved Particle Swarm Optimization for Sea Surface Temperature
  Prediction.
\newblock {\em Energies} {\bf 2020}, {\em 13},~1369, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en13061369}{\detokenize{10.3390/en13061369}}}.

\bibitem[Fuchs and Gerbi(2016)]{FUCHS2016109}
Fuchs, H.L.; Gerbi, G.P.
\newblock {Seascape-level variation in turbulence- and wave-generated
  hydrodynamic signals experienced by plankton}.
\newblock {\em Prog. Oceanogr.} {\bf 2016}, {\em 141},~109--129, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.pocean.2015.12.010}{\detokenize{10.1016/j.pocean.2015.12.010}}}.

\bibitem[da~Silva \em{et~al.}(2010)da~Silva, Ara{\'u}jo~e Silva, Cavalcanti,
  Braga~Campos, Vieira~de Azevedo, Singh, and Rodrigues~Pereira]{SILVA20101852}
da~Silva, V.D.P.R.; Ara{\'u}jo~e Silva, R.; Cavalcanti, E.P.; Braga~Campos, C.;
  Vieira~de Azevedo, P.; Singh, V.P.; Rodrigues~Pereira, E.R.
\newblock {Trends in solar radiation in NCEP/NCAR database and measurements in
  northeastern Brazil}.
\newblock {\em Sol. Energy} {\bf 2010}, {\em 84},~1852--1862, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.solener.2010.07.011}{\detokenize{10.1016/j.solener.2010.07.011}}}.

\bibitem[Gouldby \em{et~al.}(2014)Gouldby, M{\'e}ndez, Guanche, Rueda, and
  M{\'i}nguez]{GOULDBY201415}
Gouldby, B.; M{\'e}ndez, F.J.; Guanche, Y.; Rueda, A.; M{\'i}nguez, R.
\newblock {A methodology for deriving extreme nearshore sea conditions for
  structural design and flood risk analysis}.
\newblock {\em Coast. Eng.} {\bf 2014}, {\em 88},~15--26, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.coastaleng.2014.01.012}{\detokenize{10.1016/j.coastaleng.2014.01.012}}}.

\bibitem[Alizadeh \em{et~al.}(2019)Alizadeh, Jia, Nellippallil, Wang, Hao,
  Allen, and Mistree]{Alizadeh2019}
Alizadeh, R.; Jia, L.; Nellippallil, A.B.; Wang, G.; Hao, J.; Allen, J.K.;
  Mistree, F.
\newblock Ensemble of surrogates and cross-validation for rapid and accurate
  predictions using small data sets.
\newblock {\em Artif. Intell. Eng. Des. Anal. Manuf.} {\bf 2019}, {\em 33},~484–501, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1017/S089006041900026X}{\detokenize{10.1017/S089006041900026X}}}.

\bibitem[Alizadeh \em{et~al.}(2020)Alizadeh, Allen, and Mistree]{Alizadeh2020}
Alizadeh, R.; Allen, J.K.; Mistree, F.
\newblock Managing computational complexity using surrogate models: A critical
  review.
\newblock {\em Res. Eng. Des.} {\bf 2020}, {\em 31},~275–298,  
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1007/s00163-020-00336-7}{\detokenize{10.1007/s00163-020-00336-7}}}.

\bibitem[Manfren \em{et~al.}(2020)Manfren, Groppi, and
  Astiaso~Garcia]{Manfren2020}
Manfren, M.; Groppi, D.; Astiaso~Garcia, D.
\newblock Open data and energy analytics---An analysis of essential information
  for energy system planning, design and operation.
\newblock {\em Energies} {\bf 2020}, {\em 13},~2334, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.energy.2020.118803}{\detokenize{10.1016/j.energy.2020.118803}}}.

\bibitem[Dhanraj~Bokde \em{et~al.}(2020)Dhanraj~Bokde, Mundher~Yaseen, and
  Bruun~Andersen]{Neeraj2020}
Dhanraj~Bokde, N.; Mundher~Yaseen, Z.; Bruun~Andersen, G.
\newblock ForecastTB---An R Package as a Test-Bench for Time Series
  Forecasting---Application of Wind Speed and Solar Radiation Modeling.
\newblock {\em Energies} {\bf 2020}, {\em 13},~2578, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en13102578}{\detokenize{10.3390/en13102578}}}.

\bibitem[Lo \em{et~al.}(2015)Lo, Lim, and Rahman]{LO2015293}
Lo, C.K.; Lim, Y.S.; Rahman, F.A.
\newblock {New integrated simulation tool for the optimum design of bifacial
  solar panel with reflectors on a specific site}.
\newblock {\em Renew. Energy} {\bf 2015}, {\em 81},~293--307, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.renene.2015.03.047}{\detokenize{10.1016/j.renene.2015.03.047}}}.

\bibitem[Nguyen \em{et~al.}(2013)Nguyen, Prinz, Friis{\o}, Nossum, and
  Tyapin]{NGUYEN2013150}
Nguyen, T.H.; Prinz, A.; Friis{\o}, T.; Nossum, R.; Tyapin, I.
\newblock {A framework for data integration of offshore wind farms}.
\newblock {\em Renew. Energy} {\bf 2013}, {\em 60},~150--161, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.renene.2013.05.002}{\detokenize{10.1016/j.renene.2013.05.002}}}.

\bibitem[Di~Bari \em{et~al.}(2020)Di~Bari, Horn, Nienborg, Klinker,
  Kieseritzky, and Pawelz]{Roberta2020}
Di~Bari, R.; Horn, R.; Nienborg, B.; Klinker, F.; Kieseritzky, E.; Pawelz, F.
\newblock The Environmental Potential of Phase Change Materials in Building
  Applications. A Multiple Case Investigation Based on Life Cycle Assessment
  and Building Simulation.
\newblock {\em Energies} {\bf 2020}, {\em 13},~3045, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en13123045}{\detokenize{10.3390/en13123045}}}.

\bibitem[Astiaso~Garcia and Bruschi(2016)]{ASTIASOGARCIA201648}
Astiaso~Garcia, D.; Bruschi, D.
\newblock {A risk assessment tool for improving safety standards and emergency
  management in Italian onshore wind farms}.
\newblock {\em Sustain. Energy Technol. Assess.} {\bf 2016},
  {\em 18},~48--58, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.seta.2016.09.009}{\detokenize{10.1016/j.seta.2016.09.009}}}.

\bibitem[Raabe \em{et~al.}(2010)Raabe, Klein, Gonz{\'a}lez, and
  Medina]{RAABE2010213}
Raabe, A.L.A.; Klein, A.H.d.F.; Gonz{\'a}lez, M.; Medina, R.
\newblock {MEPBAY and SMC: Software tools to support different operational
  levels of headland-bay beach in coastal engineering projects}.
\newblock {\em Coast. Eng.} {\bf 2010}, {\em 57},~213--226, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.coastaleng.2009.10.008}{\detokenize{10.1016/j.coastaleng.2009.10.008}}}.

\bibitem[Motahhir \em{et~al.}(2019)Motahhir, EL~Hammoumi, EL~Ghzizal, and
  Derouich]{MOTAHHIR20199}
Motahhir, S.; EL~Hammoumi, A.; EL~Ghzizal, A.; Derouich, A.
\newblock {Open hardware/software test bench for solar tracker with virtual
  instrumentation}.
\newblock {\em Sustain. Energy Technol. Assess.} {\bf 2019},
  {\em 31},~9--16, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.seta.2018.11.003}{\detokenize{10.1016/j.seta.2018.11.003}}}.

\bibitem[Cascajo \em{et~al.}(2019)Cascajo, Garc{\'i}a, Quiles, Correcher, and
  Morant]{en12050787}
Cascajo, R.; Garc{\'i}a, E.; Quiles, E.; Correcher, A.; Morant, F.
\newblock {Integration of Marine Wave Energy Converters into Seaports: A Case
  Study in the Port of Valencia}.
\newblock {\em Energies} {\bf 2019}, {\em 12},~787, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en12050787}{\detokenize{10.3390/en12050787}}}.

\bibitem[Zeyringer \em{et~al.}(2018)Zeyringer, Fais, Keppo, and
  Price]{ZEYRINGER20181281}
Zeyringer, M.; Fais, B.; Keppo, I.; Price, J.
\newblock {The potential of marine energy technologies in the UK---Evaluation
  from a systems perspective}.
\newblock {\em Renew. Energy} {\bf 2018}, {\em 115},~1281--1293, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.renene.2017.07.092}{\detokenize{10.1016/j.renene.2017.07.092}}}.

\bibitem[{De Jong} \em{et~al.}(2019){De Jong}, Hoppe, and Noori]{en12091657}
{De Jong}, M.; Hoppe, T.; Noori, N.
\newblock {City Branding, Sustainable Urban Development and the Rentier State.
  How do Qatar, Abu Dhabi and Dubai present Themselves in the Age of Post Oil
  and Global Warming?}
\newblock {\em Energies} {\bf 2019}, {\em 12},~1657, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en12091657}{\detokenize{10.3390/en12091657}}}.

\bibitem[Brede and de~Vries(2013)]{BREDE201344}
Brede, M.; de~Vries, B.J.M.
\newblock {The energy transition in a climate-constrained world: Regional vs.
  global optimization}.
\newblock {\em Environ. Model. Softw.} {\bf 2013}, {\em
  44},~44--61, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.envsoft.2012.07.011}{\detokenize{10.1016/j.envsoft.2012.07.011}}}.

\bibitem[Alizadeh \em{et~al.}(2020)Alizadeh, Lund, and
  Soltanisehat]{Alizadeh2020a}
Alizadeh, R.; Lund, P.D.; Soltanisehat, L.
\newblock Outlook on biofuels in future studies: A systematic literature
  review.
\newblock {\em Renew. Sustain. Energy Rev.} {\bf 2020}, {\em
  134},~110326, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/doi.org/10.1016/j.rser.2020.110326}{\detokenize{10.1016/j.rser.2020.110326}}}.

\bibitem[Falc{\~a}o(2010)]{FALCAO2010899}
Falc{\~a}o, A.F.D.O.
\newblock {Wave energy utilization: A review of the technologies}.
\newblock {\em Renew. Sustain. Energy Rev.} {\bf 2010}, {\em
  14},~899--918, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.rser.2009.11.003}{\detokenize{10.1016/j.rser.2009.11.003}}}.

\bibitem[Amini \em{et~al.}(2020)Amini, Golbaz, Amini, Majidi~Nezhad, Neshat,
  and Astiaso~Garcia]{Amini2020}
Amini, E.; Golbaz, D.; Amini, F.; Majidi~Nezhad, M.; Neshat, M.;
  Astiaso~Garcia, D.
\newblock A Parametric Study of Wave Energy Converter Layouts in Real Wave
  Models.
\newblock {\em Energies} {\bf 2020}, {\em 13},~6095, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en13226095}{\detokenize{10.3390/en13226095}}}.

\bibitem[Oliveira-Pinto \em{et~al.}(2019)Oliveira-Pinto, Rosa-Santos, and
  Taveira-Pinto]{OLIVEIRAPINTO2019556}
Oliveira-Pinto, S.; Rosa-Santos, P.; Taveira-Pinto, F.
\newblock {Electricity supply to offshore oil and gas platforms from renewable
  ocean wave energy: Overview and case study analysis}.
\newblock {\em Energy Convers. Manag.} {\bf 2019}, {\em
  186},~556--569, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.enconman.2019.02.050}{\detokenize{10.1016/j.enconman.2019.02.050}}}.

\bibitem[Fern{\'a}ndez~Prieto \em{et~al.}(2019)Fern{\'a}ndez~Prieto,
  Rodr{\'i}guez~Rodr{\'i}guez, and
  Schallenberg~Rodr{\'i}guez]{FERNANDEZPRIETO2019546}
Fern{\'a}ndez~Prieto, L.; Rodr{\'i}guez~Rodr{\'i}guez, G.;
  Schallenberg~Rodr{\'i}guez, J.
\newblock {Wave energy to power a desalination plant in the north of Gran
  Canaria Island: Wave resource, socioeconomic and environmental assessment}.
\newblock {\em J. Environ. Manag.} {\bf 2019}, {\em
  231},~546--551, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.jenvman.2018.10.071}{\detokenize{10.1016/j.jenvman.2018.10.071}}}.

\bibitem[Ochi(1998)]{ochi1998}
Ochi, M.K.
\newblock {\em {Ocean Waves: The Stochastic Approach}}; {Cambridge Ocean
  Technology Series}; Cambridge University Press:  Cambridge, United Kingdom, 1998.

\bibitem[Crowley \em{et~al.}(2018)Crowley, Porter, Taunton, and
  Wilson]{CROWLEY2018159}
Crowley, S.; Porter, R.; Taunton, D.J.; Wilson, P.A.
\newblock {Modelling of the WITT wave energy converter}.
\newblock {\em Renew. Energy} {\bf 2018}, {\em 115},~159--174, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.renene.2017.08.004}{\detokenize{10.1016/j.renene.2017.08.004}}}.

\bibitem[Abdelkhalik \em{et~al.}(2016)Abdelkhalik, Robinett, Zou, Bacelli, Coe,
  Bull, Wilson, and Korde]{Abdelkhalik2016}
Abdelkhalik, O.; Robinett, R.; Zou, S.; Bacelli, G.; Coe, R.; Bull, D.; Wilson,
  D.; Korde, U.
\newblock {On the control design of wave energy converters with wave
  prediction}.
\newblock {\em J. Ocean. Eng. Mar. Energy} {\bf 2016}, {\em
  2},~473--483, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1007/s40722-016-0048-4}{\detokenize{10.1007/s40722-016-0048-4}}}.

\bibitem[Ringwood \em{et~al.}(2014)Ringwood, Bacelli, and Fusco]{6898109}
Ringwood, J.V.; Bacelli, G.; Fusco, F.
\newblock {Energy-Maximizing Control of Wave-Energy Converters: The Development
  of Control System Technology to Optimize Their Operation}.
\newblock {\em IEEE Control Syst.} {\bf 2014}, {\em 34},~30--55, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1109/MCS.2014.2333253}{\detokenize{10.1109/MCS.2014.2333253}}}.

\bibitem[Wei(2018)]{en11010011}
Wei, C.C.
\newblock {Nearshore Wave Predictions Using Data Mining Techniques during
  Typhoons: A Case Study near Taiwan{\rq}s Northeastern Coast}.
\newblock {\em Energies} {\bf 2018}, {\em 11},~11, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en11010011}{\detokenize{10.3390/en11010011}}}.

\bibitem[Kaloop \em{et~al.}(2020)Kaloop, Kumar, Zarzoura, Roy, and
  Hu]{Kaloop2020}
Kaloop, M.R.; Kumar, D.; Zarzoura, F.; Roy, B.; Hu, J.W.
\newblock A wavelet---Particle swarm optimization---Extreme learning machine
  hybrid modeling for significant wave height prediction.
\newblock {\em Ocean Eng.} {\bf 2020}, {\em 213},~107777, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/doi.org/10.1016/j.oceaneng.2020.107777}{\detokenize{10.1016/j.oceaneng.2020.107777}}}.

\bibitem[Rusu(2015)]{en80910370}
Rusu, L.
\newblock {Assessment of the Wave Energy in the Black Sea Based on a 15-Year
  Hindcast with Data Assimilation}.
\newblock {\em Energies} {\bf 2015}, {\em 8},~10370--10388, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en80910370}{\detokenize{10.3390/en80910370}}}.

\bibitem[Rhee \em{et~al.}(2014)Rhee, Park, and Inoue]{Sang-Yong2014}
Rhee, S.Y.; Park, J.; Inoue, A. (Eds.)
\newblock {\em Soft Computing in Machine Learning}; Springer: Berlin, Germany, 2014.

\bibitem[Bishop(2006)]{Bishop:2006:PRM:1162264}
Bishop, C.M.
\newblock {\em {Pattern Recognition and Machine Learning}}; Springer: New York, NY, USA,  2006.

\bibitem[Chang \em{et~al.}(2019)Chang, Hsu, and Chang]{Fi-John2019}
Chang, F.J.; Hsu, K.; Chang, L.C., Eds.
\newblock {\em Flood Forecasting Using Machine Learning Methods}; MPDI: Basel, Switzerland, 2019.

\bibitem[Dineva \em{et~al.}(2019)Dineva, Mosavi, Faizollahzadeh~Ardabili,
  Vajda, Shamshirband, Rabczuk, and Chau]{Mosavi2019}
Dineva, A.; Mosavi, A.; Faizollahzadeh~Ardabili, S.; Vajda, I.; Shamshirband,
  S.; Rabczuk, T.; Chau, K.W.
\newblock Review of Soft Computing Models in Design and Control of Rotating
  Electrical Machines.
\newblock {\em Energies} {\bf 2019}, {\em 12},~1049, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/en12061049}{\detokenize{10.3390/en12061049}}}.

\bibitem[Guo \em{et~al.}(2018)Guo, Wang, Chen, Li, Liu, Xu, Huang, and
  Huang]{GUO201816}
Guo, Y.; Wang, J.; Chen, H.; Li, G.; Liu, J.; Xu, C.; Huang, R.; Huang, Y.
\newblock {Machine learning-based thermal response time ahead energy demand
  prediction for building heating systems}.
\newblock {\em Appl. Energy} {\bf 2018}, {\em 221},~16--27, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.apenergy.2018.03.125}{\detokenize{10.1016/j.apenergy.2018.03.125}}}.

\bibitem[Frank \em{et~al.}(2016)Frank, Hall, and Witten]{WEKA}
Frank, E.; Hall, M.A.; Witten, I.H.
\newblock {\emph{The WEKA Workbench. Online Appendix for Data Mining: Practical
  Machine Learning Tools and Techniques}};  Morgan Kaufmann: Cambridge, MA, USA, 2016.


\bibitem[Dur{\'a}n-Rosal \em{et~al.}(2017)Dur{\'a}n-Rosal, Fern{\'a}ndez,
  Guti{\'e}rrez, and Herv{\'a}s-Mart{\'i}nez]{DURANROSAL2017268}
Dur{\'a}n-Rosal, A.M.; Fern{\'a}ndez, J.C.; Guti{\'e}rrez, P.A.;
  Herv{\'a}s-Mart{\'i}nez, C.
\newblock {Detection and prediction of segments containing extreme significant
  wave heights}.
\newblock {\em Ocean Eng.} {\bf 2017}, {\em 142},~268--279, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.oceaneng.2017.07.009}{\detokenize{10.1016/j.oceaneng.2017.07.009}}}.

\bibitem[Kumar \em{et~al.}(2017)Kumar, Savitha, and Al~Mamun]{KUMAR2017605}
Kumar, N.K.; Savitha, R.; Al~Mamun, A.
\newblock {Regional ocean wave height prediction using sequential learning
  neural networks}.
\newblock {\em Ocean Eng.} {\bf 2017}, {\em 129},~605--612, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.oceaneng.2016.10.033}{\detokenize{10.1016/j.oceaneng.2016.10.033}}}.

\bibitem[Ali \em{et~al.}(2020)Ali, Prasad, Xiang, and Deo]{Ali2020}
Ali, M.; Prasad, R.; Xiang, Y.; Deo, R.C.
\newblock Near real-time significant wave height forecasting with hybridized
  multiple linear regression algorithms.
\newblock {\em Renew. Sustain. Energy Rev.} {\bf 2020}, {\em
  132},~110003, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/doi.org/10.1016/j.rser.2020.110003}{\detokenize{10.1016/j.rser.2020.110003}}}.

\bibitem[Cornejo-Bueno \em{et~al.}(2016)Cornejo-Bueno, Nieto-Borge,
  García-Díaz, Rodríguez, and Salcedo-Sanz]{Cornejo-Bueno2016}
Cornejo-Bueno, L.; Nieto-Borge, J.; García-Díaz, P.; Rodríguez, G.;
  Salcedo-Sanz, S.
\newblock Significant wave height and energy flux prediction for marine energy
  applications: A grouping genetic algorithm---Extreme Learning Machine
  approach.
\newblock {\em Renew. Energy} {\bf 2016}, {\em 97},~380--389, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/doi.org/10.1016/j.renene.2016.05.094}{\detokenize{10.1016/j.renene.2016.05.094}}}.

\bibitem[Emmanouil \em{et~al.}(2020)Emmanouil, Aguilar, Nane, and
  Schouten]{Emmanouil2020}
Emmanouil, S.; Aguilar, S.G.; Nane, G.F.; Schouten, J.J.
\newblock Statistical models for improving significant wave height predictions
  in offshore operations.
\newblock {\em Ocean Eng.} {\bf 2020}, {\em 206},~107249, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/doi.org/10.1016/j.oceaneng.2020.107249}{\detokenize{10.1016/j.oceaneng.2020.107249}}}.

\bibitem[Shamshirband \em{et~al.}(2020)Shamshirband, Mosavi, Rabczuk, Nabipour,
  and wing Chau]{Shamshirband2020}
Shamshirband, S.; Mosavi, A.; Rabczuk, T.; Nabipour, N.; Wing Chau, K.
\newblock Prediction of significant wave height; comparison between nested grid
  numerical model, and machine learning models of artificial neural networks,
  extreme learning and support vector machines.
\newblock {\em Eng. Appl. Comput. Fluid Mech.} {\bf
  2020}, {\em 14},~805--817, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1080/19942060.2020.1773932}{\detokenize{10.1080/19942060.2020.1773932}}}.

\bibitem[Johansson \em{et~al.}(2015)Johansson, Epitropou, Karatzas, Karppinen,
  Wanner, Vrochidis, Bassoukos, Kukkonen, and Kompatsiaris]{JOHANSSON2015143}
Johansson, L.; Epitropou, V.; Karatzas, K.; Karppinen, A.; Wanner, L.;
  Vrochidis, S.; Bassoukos, A.; Kukkonen, J.; Kompatsiaris, I.
\newblock {Fusion of meteorological and air quality data extracted from the web
  for personalized environmental information services}.
\newblock {\em Environ. Model. Softw.} {\bf 2015}, {\em
  64},~143--155, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.envsoft.2014.11.021}{\detokenize{10.1016/j.envsoft.2014.11.021}}}.

\bibitem[Fern{\'a}ndez \em{et~al.}(2015)Fern{\'a}ndez, Salcedo-Sanz,
  Guti{\'e}rrez, Alexandre, and Herv{\'a}s-Mart{\'i}nez]{FERNANDEZ201544}
Fern{\'a}ndez, J.C.; Salcedo-Sanz, S.; Guti{\'e}rrez, P.A.; Alexandre, E.;
  Herv{\'a}s-Mart{\'i}nez, C.
\newblock {Significant wave height and energy flux range forecast with machine
  learning classifiers}.
\newblock {\em Eng. Appl. Artif. Intell.} {\bf 2015},
  {\em 43},~44--53, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.engappai.2015.03.012}{\detokenize{10.1016/j.engappai.2015.03.012}}}.

\bibitem[Adams and Flora(2010)]{Adams2010}
Adams, J.; Flora, S.
\newblock {Correlating seabird movements with ocean winds: linking satellite
  telemetry with ocean scatterometry}.
\newblock {\em Mar. Biol.} {\bf 2010}, {\em 157},~915--929, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1007/s00227-009-1367-y}{\detokenize{10.1007/s00227-009-1367-y}}}.

\bibitem[{National Data Buoy Center}()]{NOAA}
{National Data Buoy Center}.
\newblock {National Oceanic and Atmospheric Administration of the USA (NOAA)}.
\newblock  Available online: \url{http://www.ndbc.noaa.gov/}
\newblock {(accessed on 10 December 2020)}.

\bibitem[Kalnay \em{et~al.}(1996)Kalnay, Kanamitsu, Kistler, Collins, Deaven,
  Gandin, Iredell, Saha, White, Woollen, Zhu, Leetmaa, Reynolds, Chelliah,
  Ebisuzaki, Higgins, Janowiak, Mo, Ropelewski, Wang, Jenne, and
  Joseph]{Kalnay1996}
Kalnay, E.; Kanamitsu, M.; Kistler, R.; Collins, W.; Deaven, D.; Gandin, L.;
  Iredell, M.; Saha, S.; White, G.; Woollen, J.; et al.
\newblock {The NCEP/NCAR 40-Year Reanalysis Project}.
\newblock {\em Bull. Am. Meteorol. Soc.} {\bf 1996},
  {\em 77},~437--471, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2}{\detokenize{10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2}}}.

\bibitem[Kistler \em{et~al.}(2001)Kistler, Collins, Saha, White, Woollen,
  Kalnay, Chelliah, Ebisuzaki, Kanamitsu, Kousky, van~den Dool, Jenne, and
  Fiorino]{Kistler2001}
Kistler, R.; Collins, W.; Saha, S.; White, G.; Woollen, J.; Kalnay, E.;
  Chelliah, M.; Ebisuzaki, W.; Kanamitsu, M.; Kousky, V.; et al.
\newblock {The NCEP--NCAR 50--Year Reanalysis: Monthly Means CD--ROM and
  Documentation}.
\newblock {\em Bull. Am. Meteorol. Soc.} {\bf 2001},
  {\em 82},~247--267, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1175/1520-0477(2001)082<0247:TNNYRM>2.3.CO;2}{\detokenize{10.1175/1520-0477(2001)082<0247:TNNYRM>2.3.CO;2}}}.

\bibitem[WEK()]{WEKA_ARFF}
{The WEKA Data Mining Software: {Attribute-Relation File Format (ARFF)}}.
\newblock Available online: \url{https://www.cs.waikato.ac.nz/ml/weka/arff.html}
\newblock {(accessed  on 10 December 2020)}.

\bibitem[Ali and Prasad(2019)]{Ali2019}
Ali, M.; Prasad, R.
\newblock Significant wave height forecasting via an extreme learning machine
  model integrated with improved complete ensemble empirical mode
  decomposition.
\newblock {\em Renew. Sustain. Energy Rev.} {\bf 2019}, {\em
  104},~281--295, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.rser.2019.01.014}{\detokenize{10.1016/j.rser.2019.01.014}}}.

\bibitem[Chatziioannou \em{et~al.}(2017)Chatziioannou, Katsardi, Koukouselis,
  and Mistakidis]{CHATZIIOANNOU2017126}
Chatziioannou, K.; Katsardi, V.; Koukouselis, A.; Mistakidis, E.
\newblock {The effect of nonlinear wave-structure and soil-structure
  interactions in the design of an offshore structure}.
\newblock {\em Mar. Struct.} {\bf 2017}, {\em 52},~126--152, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.marstruc.2016.11.003}{\detokenize{10.1016/j.marstruc.2016.11.003}}}.

\bibitem[Dalgic \em{et~al.}(2015)Dalgic, Lazakis, Dinwoodie, McMillan, and
  Revie]{DALGIC2015211}
Dalgic, Y.; Lazakis, I.; Dinwoodie, I.; McMillan, D.; Revie, M.
\newblock {Advanced logistics planning for offshore wind farm operation and
  maintenance activities}.
\newblock {\em Ocean Eng.} {\bf 2015}, {\em 101},~211--226, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.oceaneng.2015.04.040}{\detokenize{10.1016/j.oceaneng.2015.04.040}}}.

\bibitem[Spaulding \em{et~al.}(2016)Spaulding, Grilli, Damon, Crean, Fugate,
  Oakley, and Stempel]{Spaulding2020}
Spaulding, M.L.; Grilli, A.; Damon, C.; Crean, T.; Fugate, G.; Oakley, B.A.;
  Stempel, P.
\newblock STORMTOOLS: Coastal Environmental Risk Index (CERI).
\newblock {\em J. Mar. Sci. Eng.} {\bf 2016}, {\em
  4},~54, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.3390/jmse4030054}{\detokenize{10.3390/jmse4030054}}}.

\bibitem[{National Data Buoy Center}({\natexlab{a}})]{NOAA_1}
{National Data Buoy Center}.
\newblock {NDBC---Historical NDBC Data}.
\newblock Available online: \url{http://www.ndbc.noaa.gov/historical\_data.shtml}
\newblock {(accessed on 10 December 2020)}.

\bibitem[{National Data Buoy Center}({\natexlab{b}})]{NOAA_2}
{National Data Buoy Center}.
\newblock {NDBC---Important NDBC Web Site Changes}.
\newblock Available online:  \url{http://www.ndbc.noaa.gov/mods.shtml}
\newblock {(accessed on 10 December 2020)}.

\bibitem[{National Data Buoy Center}({\natexlab{c}})]{NOAA_4}
{National Data Buoy Center}.
\newblock {Measurement Descriptions and Units}.
\newblock Available online: \url{https://www.ndbc.noaa.gov/measdes.shtml#stdmet}
\newblock (accessed on 10 December 2020).

\bibitem[{NOAA/OAR/ESRL PSD}()]{NNRP}
{NOAA/OAR/ESRL PSD}.
\newblock {ESRL : PSD : NCEP/NCAR Reanalysis 1}.
\newblock
  Available online: \url{https://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html}
\newblock {(accessed on 15 January 2019)}.

\bibitem[{Unidata}(2017)]{NetCDF}
{Unidata}.
\newblock {\emph{Network Common Data Form (NetCDF) Version 4.6.10 [Software]};
  UCAR/Unidata: Boulder, CO, USA},  2017;
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.5065/D6H70CW6}{\detokenize{10.5065/D6H70CW6}}}.

\bibitem[de~Smith \em{et~al.}(2009)de~Smith, Goodchild, and
  Longley]{Haversine_2009}
de~Smith, M.J.; Goodchild, M.F.; Longley, P.A.
\newblock {\em {Geospatial Analysis: A Comprehensive Guide to Principles,
  Techniques and Software Tools}}, 3rd ed.; Matador:  Leicester, United Kingdom, 2009.

\bibitem[{Hosmer Jr} \em{et~al.}(2013){Hosmer Jr}, Lemeshow, and
  Sturdivant]{hosmer2013applied}
{Hosmer}, D.W., Jr.; Lemeshow, S.; Sturdivant, R.X.
\newblock {\em {Applied Logistic Regression}}, 3rd ed.; John Wiley \& Sons: New Jersey, USA, 2013.

\bibitem[Quinlan(1992)]{quinlan2014c4}
Quinlan, J.R.
\newblock {\em {C4. 5: Programs for Machine Learning}}; Morgan Kaufmann:  Burlington, Massachusetts, USA, 1992.

\bibitem[Breiman(2001)]{breiman2001random}
Breiman, L.
\newblock {Random forests}.
\newblock {\em Mach. Learn.} {\bf 2001}, {\em 45},~5--32, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1023/A:1010933404324}{\detokenize{10.1023/A:1010933404324}}}.

\bibitem[Cortes and Vapnik(1995)]{cortes1995support}
Cortes, C.; Vapnik, V.
\newblock {Support-vector networks}.
\newblock {\em Mach. Learn.} {\bf 1995}, {\em 20},~273--297, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1007/BF00994018}{\detokenize{10.1007/BF00994018}}}.

\bibitem[Haykin(1994)]{haykin1994neural}
Haykin, S.
\newblock {\em {Neural Networks: A Comprehensive Foundation}}; Prentice Hall
  PTR:  New Jersey, USA, 1994.

\bibitem[{National Data Buoy Center}()]{NOAA_3}
{National Data Buoy Center}.
\newblock {NDBC---Measurement Descriptions and Units}.
\newblock  Available online: \url{https://www.ndbc.noaa.gov/measdes.shtml}
\newblock {(accessed on 10 December 2020)}.

\bibitem[Dur{\'a}n-Rosal \em{et~al.}(2016)Dur{\'a}n-Rosal,
  Herv{\'a}s-Mart{\'i}nez, Tall{\'o}n-Ballesteros, Mart{\'i}nez-Estudillo, and
  Salcedo-Sanz]{DuranRosal2016}
Dur{\'a}n-Rosal, A.M.; Herv{\'a}s-Mart{\'i}nez, C.; Tall{\'o}n-Ballesteros,
  A.J.; Mart{\'i}nez-Estudillo, A.C.; Salcedo-Sanz, S.
\newblock {{M}assive missing data reconstruction in ocean buoys with
  evolutionary product unit neural networks}.
\newblock {\em Ocean Eng.} {\bf 2016}, {\em 117},~292--301, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1016/j.oceaneng.2016.03.053}{\detokenize{10.1016/j.oceaneng.2016.03.053}}}.

\bibitem[Alcal{\'a}-Fdez \em{et~al.}(2009)Alcal{\'a}-Fdez, S{\'a}nchez,
  Garc{\'i}a, del Jes{\'u}s, Ventura, Garrell, Otero, Romero, Bacardit, Rivas,
  Fern{\'a}ndez, and Herrera]{AlcalFdez2009KEELAS}
Alcal{\'a}-Fdez, J.; S{\'a}nchez, L.; Garc{\'i}a, S.; del Jes{\'u}s, M.J.;
  Ventura, S.; Garrell, J.M.; Otero, J.; Romero, C.; Bacardit, J.; Rivas, V.M.;
  et al.
\newblock {KEEL: A software tool to assess evolutionary algorithms for data
  mining problems}.
\newblock {\em Soft Comput.} {\bf 2009}, {\em 13},~307--318, 
\newblock
  doi:{\changeurlcolor{black}\href{https://doi.org/10.1007/s00500-008-0323-y}{\detokenize{10.1007/s00500-008-0323-y}}}.

\end{thebibliography}

%=====================================
% References, variant B: internal bibliography
%=====================================
%\begin{thebibliography}{999}
% Reference 1
%\bibitem[Author1(year)]{ref-journal}
%Author1, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142--149.
% Reference 2
%\bibitem[Author2(year)]{ref-book}
%Author2, L. The title of the cited contribution. In {\em The Book Title}; Editor1, F., Editor2, A., Eds.; Publishing House: City, Country, 2007; pp. 32--58.
%\end{thebibliography}

% The following MDPI journals use author-date citation: Arts, Econometrics, Economies, Genealogy, Humanities, IJFS, JRFM, Laws, Religions, Risks, Social Sciences. For those journals, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\sampleavailability{Samples of the compounds ...... are available from the authors.}

%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

